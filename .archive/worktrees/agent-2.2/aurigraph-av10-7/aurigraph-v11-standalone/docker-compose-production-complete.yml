# Complete Production Docker Compose Configuration\n# Includes Aurigraph V11, monitoring, logging, and supporting services\n\nversion: '3.8'\n\nnetworks:\n  aurigraph-production:\n    driver: bridge\n    ipam:\n      config:\n        - subnet: 172.20.0.0/16\n  monitoring:\n    driver: bridge\n  logging:\n    driver: bridge\n\nvolumes:\n  # Aurigraph data volumes\n  aurigraph-data-1:\n    driver: local\n  aurigraph-data-2:\n    driver: local\n  aurigraph-data-3:\n    driver: local\n  aurigraph-logs:\n    driver: local\n  \n  # Monitoring volumes\n  prometheus-data:\n    driver: local\n  grafana-data:\n    driver: local\n  alertmanager-data:\n    driver: local\n  \n  # Logging volumes\n  elasticsearch-data:\n    driver: local\n  logstash-data:\n    driver: local\n  \n  # Database volumes\n  postgres-data:\n    driver: local\n  redis-data:\n    driver: local\n\nservices:\n  # ==========================================================================\n  # Aurigraph V11 Production Cluster (3 nodes for HA)\n  # ==========================================================================\n  \n  aurigraph-v11-node-1:\n    build:\n      context: .\n      dockerfile: Dockerfile.production\n      args:\n        BUILD_TYPE: native-ultra\n        JAVA_VERSION: 21\n    image: aurigraph/v11-native-ultra:latest\n    container_name: aurigraph-v11-node-1\n    hostname: aurigraph-node-1\n    restart: unless-stopped\n    networks:\n      aurigraph-production:\n        ipv4_address: 172.20.1.10\n    ports:\n      - \"9003:9003\"  # HTTP\n      - \"9004:9004\"  # gRPC\n    volumes:\n      - aurigraph-data-1:/app/data\n      - aurigraph-logs:/app/logs\n      - ./config/production:/app/config:ro\n      - ./config/ssl:/app/ssl:ro\n    environment:\n      QUARKUS_PROFILE: production\n      AURIGRAPH_NODE_ID: node-1\n      AURIGRAPH_CLUSTER_SIZE: 3\n      AURIGRAPH_CLUSTER_NODES: \"aurigraph-node-1:9004,aurigraph-node-2:9004,aurigraph-node-3:9004\"\n      CONSENSUS_LEADER_PREFERENCE: primary\n      AI_OPTIMIZATION_ENABLED: \"true\"\n      AI_OPTIMIZATION_TARGET_TPS: 3500000\n      QUANTUM_CRYPTO_ENABLED: \"true\"\n      PERFORMANCE_ULTRA_MODE: \"true\"\n      MALLOC_ARENA_MAX: 2\n      MALLOC_MMAP_THRESHOLD_: 65536\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:9003/q/health\"]\n      interval: 10s\n      timeout: 5s\n      retries: 3\n      start_period: 5s\n    deploy:\n      resources:\n        limits:\n          cpus: '8.0'\n          memory: 4G\n        reservations:\n          cpus: '2.0'\n          memory: 1G\n    depends_on:\n      - postgres\n      - redis\n      - prometheus\n    labels:\n      - \"traefik.enable=true\"\n      - \"traefik.http.routers.aurigraph-v11.rule=Host(`api.aurigraph.io`)\"\n      - \"traefik.http.services.aurigraph-v11.loadbalancer.server.port=9003\"\n      - \"traefik.http.routers.aurigraph-v11.tls=true\"\n      - \"traefik.http.routers.aurigraph-v11.tls.certresolver=letsencrypt\"\n  \n  aurigraph-v11-node-2:\n    build:\n      context: .\n      dockerfile: Dockerfile.production\n      args:\n        BUILD_TYPE: native-ultra\n        JAVA_VERSION: 21\n    image: aurigraph/v11-native-ultra:latest\n    container_name: aurigraph-v11-node-2\n    hostname: aurigraph-node-2\n    restart: unless-stopped\n    networks:\n      aurigraph-production:\n        ipv4_address: 172.20.1.11\n    ports:\n      - \"9013:9003\"  # HTTP\n      - \"9014:9004\"  # gRPC\n    volumes:\n      - aurigraph-data-2:/app/data\n      - aurigraph-logs:/app/logs\n      - ./config/production:/app/config:ro\n      - ./config/ssl:/app/ssl:ro\n    environment:\n      QUARKUS_PROFILE: production\n      AURIGRAPH_NODE_ID: node-2\n      AURIGRAPH_CLUSTER_SIZE: 3\n      AURIGRAPH_CLUSTER_NODES: \"aurigraph-node-1:9004,aurigraph-node-2:9004,aurigraph-node-3:9004\"\n      CONSENSUS_LEADER_PREFERENCE: secondary\n      AI_OPTIMIZATION_ENABLED: \"true\"\n      AI_OPTIMIZATION_TARGET_TPS: 3500000\n      QUANTUM_CRYPTO_ENABLED: \"true\"\n      PERFORMANCE_ULTRA_MODE: \"true\"\n      MALLOC_ARENA_MAX: 2\n      MALLOC_MMAP_THRESHOLD_: 65536\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:9003/q/health\"]\n      interval: 10s\n      timeout: 5s\n      retries: 3\n      start_period: 5s\n    deploy:\n      resources:\n        limits:\n          cpus: '8.0'\n          memory: 4G\n        reservations:\n          cpus: '2.0'\n          memory: 1G\n    depends_on:\n      - postgres\n      - redis\n      - prometheus\n  \n  aurigraph-v11-node-3:\n    build:\n      context: .\n      dockerfile: Dockerfile.production\n      args:\n        BUILD_TYPE: native-ultra\n        JAVA_VERSION: 21\n    image: aurigraph/v11-native-ultra:latest\n    container_name: aurigraph-v11-node-3\n    hostname: aurigraph-node-3\n    restart: unless-stopped\n    networks:\n      aurigraph-production:\n        ipv4_address: 172.20.1.12\n    ports:\n      - \"9023:9003\"  # HTTP\n      - \"9024:9004\"  # gRPC\n    volumes:\n      - aurigraph-data-3:/app/data\n      - aurigraph-logs:/app/logs\n      - ./config/production:/app/config:ro\n      - ./config/ssl:/app/ssl:ro\n    environment:\n      QUARKUS_PROFILE: production\n      AURIGRAPH_NODE_ID: node-3\n      AURIGRAPH_CLUSTER_SIZE: 3\n      AURIGRAPH_CLUSTER_NODES: \"aurigraph-node-1:9004,aurigraph-node-2:9004,aurigraph-node-3:9004\"\n      CONSENSUS_LEADER_PREFERENCE: tertiary\n      AI_OPTIMIZATION_ENABLED: \"true\"\n      AI_OPTIMIZATION_TARGET_TPS: 3500000\n      QUANTUM_CRYPTO_ENABLED: \"true\"\n      PERFORMANCE_ULTRA_MODE: \"true\"\n      MALLOC_ARENA_MAX: 2\n      MALLOC_MMAP_THRESHOLD_: 65536\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:9003/q/health\"]\n      interval: 10s\n      timeout: 5s\n      retries: 3\n      start_period: 5s\n    deploy:\n      resources:\n        limits:\n          cpus: '8.0'\n          memory: 4G\n        reservations:\n          cpus: '2.0'\n          memory: 1G\n    depends_on:\n      - postgres\n      - redis\n      - prometheus\n\n  # ==========================================================================\n  # Load Balancer (Traefik)\n  # ==========================================================================\n  \n  traefik:\n    image: traefik:v3.0\n    container_name: aurigraph-traefik\n    restart: unless-stopped\n    networks:\n      - aurigraph-production\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n      - \"8080:8080\"  # Traefik dashboard\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock:ro\n      - ./config/traefik/traefik.yml:/traefik.yml:ro\n      - ./config/traefik/dynamic:/dynamic:ro\n      - ./config/ssl/acme.json:/acme.json\n    environment:\n      - CF_API_EMAIL=${CLOUDFLARE_EMAIL}\n      - CF_DNS_API_TOKEN=${CLOUDFLARE_TOKEN}\n    labels:\n      - \"traefik.enable=true\"\n      - \"traefik.http.routers.traefik.rule=Host(`traefik.aurigraph.io`)\"\n      - \"traefik.http.services.traefik.loadbalancer.server.port=8080\"\n      - \"traefik.http.routers.traefik.tls=true\"\n      - \"traefik.http.routers.traefik.tls.certresolver=letsencrypt\"\n\n  # ==========================================================================\n  # Database Services\n  # ==========================================================================\n  \n  postgres:\n    image: postgres:16-alpine\n    container_name: aurigraph-postgres\n    restart: unless-stopped\n    networks:\n      - aurigraph-production\n    environment:\n      POSTGRES_DB: aurigraph_production\n      POSTGRES_USER: aurigraph\n      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-aurigraph-prod-password}\n      POSTGRES_INITDB_ARGS: \"--auth-local=trust --auth-host=md5\"\n    volumes:\n      - postgres-data:/var/lib/postgresql/data\n      - ./config/postgres/init.sql:/docker-entrypoint-initdb.d/init.sql:ro\n      - ./config/postgres/postgresql.conf:/etc/postgresql/postgresql.conf:ro\n    ports:\n      - \"5432:5432\"\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U aurigraph\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n    deploy:\n      resources:\n        limits:\n          cpus: '2.0'\n          memory: 2G\n        reservations:\n          cpus: '0.5'\n          memory: 512M\n  \n  redis:\n    image: redis:7-alpine\n    container_name: aurigraph-redis\n    restart: unless-stopped\n    networks:\n      - aurigraph-production\n    ports:\n      - \"6379:6379\"\n    volumes:\n      - redis-data:/data\n      - ./config/redis/redis.conf:/usr/local/etc/redis/redis.conf:ro\n    command: redis-server /usr/local/etc/redis/redis.conf\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n    deploy:\n      resources:\n        limits:\n          cpus: '1.0'\n          memory: 1G\n        reservations:\n          cpus: '0.25'\n          memory: 256M\n\n  # ==========================================================================\n  # Monitoring Stack\n  # ==========================================================================\n  \n  prometheus:\n    image: prom/prometheus:v2.48.0\n    container_name: aurigraph-prometheus\n    restart: unless-stopped\n    networks:\n      - aurigraph-production\n      - monitoring\n    ports:\n      - \"9090:9090\"\n    volumes:\n      - prometheus-data:/prometheus\n      - ./config/prometheus/prometheus-production.yml:/etc/prometheus/prometheus.yml:ro\n      - ./config/prometheus/rules:/etc/prometheus/rules:ro\n    command:\n      - '--config.file=/etc/prometheus/prometheus.yml'\n      - '--storage.tsdb.path=/prometheus'\n      - '--storage.tsdb.retention.time=30d'\n      - '--storage.tsdb.retention.size=50GB'\n      - '--web.console.libraries=/etc/prometheus/console_libraries'\n      - '--web.console.templates=/etc/prometheus/consoles'\n      - '--web.enable-lifecycle'\n      - '--web.enable-admin-api'\n      - '--storage.tsdb.no-lockfile'\n    healthcheck:\n      test: [\"CMD\", \"wget\", \"--no-verbose\", \"--tries=1\", \"--spider\", \"http://localhost:9090/-/healthy\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n    deploy:\n      resources:\n        limits:\n          cpus: '2.0'\n          memory: 4G\n        reservations:\n          cpus: '0.5'\n          memory: 1G\n    labels:\n      - \"traefik.enable=true\"\n      - \"traefik.http.routers.prometheus.rule=Host(`prometheus.aurigraph.io`)\"\n      - \"traefik.http.services.prometheus.loadbalancer.server.port=9090\"\n      - \"traefik.http.routers.prometheus.tls=true\"\n      - \"traefik.http.routers.prometheus.tls.certresolver=letsencrypt\"\n  \n  grafana:\n    image: grafana/grafana:10.2.0\n    container_name: aurigraph-grafana\n    restart: unless-stopped\n    networks:\n      - monitoring\n      - aurigraph-production\n    ports:\n      - \"3000:3000\"\n    volumes:\n      - grafana-data:/var/lib/grafana\n      - ./config/grafana/grafana.ini:/etc/grafana/grafana.ini:ro\n      - ./config/grafana/dashboards:/var/lib/grafana/dashboards:ro\n      - ./config/grafana/provisioning:/etc/grafana/provisioning:ro\n    environment:\n      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-aurigraph-admin}\n      GF_USERS_ALLOW_SIGN_UP: false\n      GF_SMTP_ENABLED: true\n      GF_SMTP_HOST: ${SMTP_HOST:-smtp.gmail.com:587}\n      GF_SMTP_USER: ${SMTP_USER}\n      GF_SMTP_PASSWORD: ${SMTP_PASSWORD}\n      GF_SMTP_FROM_ADDRESS: alerts@aurigraph.io\n    healthcheck:\n      test: [\"CMD-SHELL\", \"curl -f http://localhost:3000/api/health || exit 1\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n    depends_on:\n      - prometheus\n    deploy:\n      resources:\n        limits:\n          cpus: '1.0'\n          memory: 1G\n        reservations:\n          cpus: '0.25'\n          memory: 256M\n    labels:\n      - \"traefik.enable=true\"\n      - \"traefik.http.routers.grafana.rule=Host(`grafana.aurigraph.io`)\"\n      - \"traefik.http.services.grafana.loadbalancer.server.port=3000\"\n      - \"traefik.http.routers.grafana.tls=true\"\n      - \"traefik.http.routers.grafana.tls.certresolver=letsencrypt\"\n  \n  alertmanager:\n    image: prom/alertmanager:v0.26.0\n    container_name: aurigraph-alertmanager\n    restart: unless-stopped\n    networks:\n      - monitoring\n    ports:\n      - \"9093:9093\"\n    volumes:\n      - alertmanager-data:/alertmanager\n      - ./config/alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro\n      - ./config/alertmanager/templates:/etc/alertmanager/templates:ro\n    command:\n      - '--config.file=/etc/alertmanager/alertmanager.yml'\n      - '--storage.path=/alertmanager'\n      - '--web.external-url=https://alerts.aurigraph.io'\n      - '--cluster.advertise-address=0.0.0.0:9093'\n    healthcheck:\n      test: [\"CMD\", \"wget\", \"--no-verbose\", \"--tries=1\", \"--spider\", \"http://localhost:9093/-/healthy\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n    deploy:\n      resources:\n        limits:\n          cpus: '0.5'\n          memory: 512M\n        reservations:\n          cpus: '0.1'\n          memory: 128M\n    labels:\n      - \"traefik.enable=true\"\n      - \"traefik.http.routers.alertmanager.rule=Host(`alerts.aurigraph.io`)\"\n      - \"traefik.http.services.alertmanager.loadbalancer.server.port=9093\"\n      - \"traefik.http.routers.alertmanager.tls=true\"\n      - \"traefik.http.routers.alertmanager.tls.certresolver=letsencrypt\"\n  \n  node-exporter:\n    image: prom/node-exporter:v1.6.1\n    container_name: aurigraph-node-exporter\n    restart: unless-stopped\n    networks:\n      - monitoring\n    ports:\n      - \"9100:9100\"\n    volumes:\n      - /proc:/host/proc:ro\n      - /sys:/host/sys:ro\n      - /:/rootfs:ro\n    command:\n      - '--path.procfs=/host/proc'\n      - '--path.rootfs=/rootfs'\n      - '--path.sysfs=/host/sys'\n      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'\n    deploy:\n      resources:\n        limits:\n          cpus: '0.2'\n          memory: 256M\n        reservations:\n          cpus: '0.05'\n          memory: 64M\n\n  # ==========================================================================\n  # Logging Stack (ELK)\n  # ==========================================================================\n  \n  elasticsearch:\n    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0\n    container_name: aurigraph-elasticsearch\n    restart: unless-stopped\n    networks:\n      - logging\n    ports:\n      - \"9200:9200\"\n      - \"9300:9300\"\n    environment:\n      - discovery.type=single-node\n      - cluster.name=aurigraph-logs\n      - node.name=aurigraph-es-1\n      - bootstrap.memory_lock=true\n      - \"ES_JAVA_OPTS=-Xms2g -Xmx2g\"\n      - xpack.security.enabled=false\n      - xpack.monitoring.collection.enabled=true\n    volumes:\n      - elasticsearch-data:/usr/share/elasticsearch/data\n      - ./config/elasticsearch/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro\n    ulimits:\n      memlock:\n        soft: -1\n        hard: -1\n    healthcheck:\n      test: [\"CMD-SHELL\", \"curl -f http://localhost:9200/_cluster/health || exit 1\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n    deploy:\n      resources:\n        limits:\n          cpus: '2.0'\n          memory: 4G\n        reservations:\n          cpus: '1.0'\n          memory: 2G\n  \n  logstash:\n    image: docker.elastic.co/logstash/logstash:8.11.0\n    container_name: aurigraph-logstash\n    restart: unless-stopped\n    networks:\n      - logging\n      - aurigraph-production\n    ports:\n      - \"5044:5044\"  # Beats input\n      - \"5000:5000\"  # TCP input\n      - \"12201:12201/udp\"  # GELF input\n    volumes:\n      - logstash-data:/usr/share/logstash/data\n      - ./config/logstash/logstash.yml:/usr/share/logstash/config/logstash.yml:ro\n      - ./config/logstash/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro\n      - ./config/logstash/pipeline:/usr/share/logstash/pipeline:ro\n    environment:\n      LS_JAVA_OPTS: \"-Xmx1g -Xms1g\"\n    depends_on:\n      - elasticsearch\n    healthcheck:\n      test: [\"CMD-SHELL\", \"curl -f http://localhost:9600 || exit 1\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n    deploy:\n      resources:\n        limits:\n          cpus: '1.0'\n          memory: 2G\n        reservations:\n          cpus: '0.5'\n          memory: 1G\n  \n  kibana:\n    image: docker.elastic.co/kibana/kibana:8.11.0\n    container_name: aurigraph-kibana\n    restart: unless-stopped\n    networks:\n      - logging\n    ports:\n      - \"5601:5601\"\n    environment:\n      ELASTICSEARCH_HOSTS: http://elasticsearch:9200\n      SERVER_NAME: kibana.aurigraph.io\n      SERVER_HOST: 0.0.0.0\n    volumes:\n      - ./config/kibana/kibana.yml:/usr/share/kibana/config/kibana.yml:ro\n    depends_on:\n      - elasticsearch\n    healthcheck:\n      test: [\"CMD-SHELL\", \"curl -f http://localhost:5601/api/status || exit 1\"]\n      interval: 30s\n      timeout: 10s\n      retries: 5\n      start_period: 60s\n    deploy:\n      resources:\n        limits:\n          cpus: '1.0'\n          memory: 2G\n        reservations:\n          cpus: '0.5'\n          memory: 1G\n    labels:\n      - \"traefik.enable=true\"\n      - \"traefik.http.routers.kibana.rule=Host(`logs.aurigraph.io`)\"\n      - \"traefik.http.services.kibana.loadbalancer.server.port=5601\"\n      - \"traefik.http.routers.kibana.tls=true\"\n      - \"traefik.http.routers.kibana.tls.certresolver=letsencrypt\"\n\n  # ==========================================================================\n  # Distributed Tracing (Jaeger)\n  # ==========================================================================\n  \n  jaeger:\n    image: jaegertracing/all-in-one:1.51\n    container_name: aurigraph-jaeger\n    restart: unless-stopped\n    networks:\n      - monitoring\n      - aurigraph-production\n    ports:\n      - \"16686:16686\"  # Jaeger UI\n      - \"14268:14268\"  # HTTP collector\n      - \"14250:14250\"  # gRPC collector\n      - \"6831:6831/udp\"  # Jaeger agent\n    environment:\n      COLLECTOR_OTLP_ENABLED: true\n      COLLECTOR_ZIPKIN_HOST_PORT: :9411\n    healthcheck:\n      test: [\"CMD-SHELL\", \"wget --no-verbose --tries=1 --spider http://localhost:16686/ || exit 1\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n    deploy:\n      resources:\n        limits:\n          cpus: '1.0'\n          memory: 1G\n        reservations:\n          cpus: '0.25'\n          memory: 256M\n    labels:\n      - \"traefik.enable=true\"\n      - \"traefik.http.routers.jaeger.rule=Host(`tracing.aurigraph.io`)\"\n      - \"traefik.http.services.jaeger.loadbalancer.server.port=16686\"\n      - \"traefik.http.routers.jaeger.tls=true\"\n      - \"traefik.http.routers.jaeger.tls.certresolver=letsencrypt\"\n\n  # ==========================================================================\n  # Service Discovery (Consul)\n  # ==========================================================================\n  \n  consul:\n    image: consul:1.17\n    container_name: aurigraph-consul\n    restart: unless-stopped\n    networks:\n      - aurigraph-production\n    ports:\n      - \"8500:8500\"\n      - \"8600:8600/udp\"\n    volumes:\n      - ./config/consul/consul.hcl:/consul/config/consul.hcl:ro\n    command: agent -config-file=/consul/config/consul.hcl\n    healthcheck:\n      test: [\"CMD\", \"consul\", \"members\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n    deploy:\n      resources:\n        limits:\n          cpus: '0.5'\n          memory: 512M\n        reservations:\n          cpus: '0.1'\n          memory: 128M\n    labels:\n      - \"traefik.enable=true\"\n      - \"traefik.http.routers.consul.rule=Host(`consul.aurigraph.io`)\"\n      - \"traefik.http.services.consul.loadbalancer.server.port=8500\"\n      - \"traefik.http.routers.consul.tls=true\"\n      - \"traefik.http.routers.consul.tls.certresolver=letsencrypt\"\n\n  # ==========================================================================\n  # Security Scanning (Falco)\n  # ==========================================================================\n  \n  falco:\n    image: falcosecurity/falco-no-driver:0.36.2\n    container_name: aurigraph-falco\n    restart: unless-stopped\n    networks:\n      - monitoring\n    privileged: true\n    volumes:\n      - /var/run/docker.sock:/host/var/run/docker.sock:ro\n      - /proc:/host/proc:ro\n      - /boot:/host/boot:ro\n      - /lib/modules:/host/lib/modules:ro\n      - /usr:/host/usr:ro\n      - /etc:/host/etc:ro\n      - ./config/falco/falco.yaml:/etc/falco/falco.yaml:ro\n      - ./config/falco/rules:/etc/falco/rules:ro\n    environment:\n      FALCO_GRPC_ENABLED: true\n      FALCO_GRPC_BIND_ADDRESS: 0.0.0.0:5060\n    deploy:\n      resources:\n        limits:\n          cpus: '0.5'\n          memory: 512M\n        reservations:\n          cpus: '0.1'\n          memory: 128M\n\n  # ==========================================================================\n  # Performance Testing (Optional)\n  # ==========================================================================\n  \n  jmeter:\n    image: justb4/jmeter:5.6.2\n    container_name: aurigraph-jmeter\n    restart: \"no\"\n    networks:\n      - aurigraph-production\n    volumes:\n      - ./test/jmeter:/test:ro\n      - ./test/results:/results\n    environment:\n      JMETER_HOME: /opt/apache-jmeter-5.6.2\n    profiles:\n      - testing\n    command: >\n      sh -c \"\n        echo 'Starting JMeter load test against Aurigraph V11 production cluster...'\n        jmeter -n -t /test/aurigraph-2m-tps-load-test.jmx \n               -l /results/jmeter-results-$$(date +%Y%m%d-%H%M%S).jtl \n               -e -o /results/dashboard-$$(date +%Y%m%d-%H%M%S) \n               -JHOST=aurigraph-v11-node-1 \n               -JPORT=9003 \n               -JTHREADS=1000 \n               -JRAMPUP=60 \n               -JDURATION=300\n      \"\n    deploy:\n      resources:\n        limits:\n          cpus: '4.0'\n          memory: 4G\n        reservations:\n          cpus: '2.0'\n          memory: 2G\n"