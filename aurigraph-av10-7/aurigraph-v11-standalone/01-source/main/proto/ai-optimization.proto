syntax = "proto3";

package io.aurigraph.v11.proto;

import "common.proto";

// ========================================================================
// Story 9, Phase 1: AI Optimization gRPC Service
// ========================================================================
// ML-driven optimization for 2M+ TPS platform capability
// - Real-time transaction ordering optimization
// - Predictive resource usage forecasting
// - Adaptive scaling recommendations
// - Online learning from live blockchain data
// ========================================================================

/**
 * AIOptimizationGrpcService: Machine Learning Optimization Engine
 *
 * Provides ML-based optimizations to maximize platform throughput
 *
 * RPC Methods (6 total):
 * 1. optimizeTransactionOrder (Client Streaming) - ML-based transaction ordering
 * 2. predictResourceUsage (Unary) - Predict resource requirements
 * 3. suggestScaling (Unary) - Recommend cluster scaling
 * 4. updateMLModel (Client Streaming) - Update ML models
 * 5. trainOnHistoricalData (Server Streaming) - Train on blockchain history
 * 6. checkHealth (Unary) - Service health check
 *
 * AI/ML Components:
 * - TransactionScoringModel: Scores transactions for optimal ordering
 * - MLLoadBalancer: Assigns shards based on load prediction
 * - OnlineLearningService: Continuous model updates from live data
 * - PredictiveScaling: Forecasts resource needs
 *
 * Performance Impact:
 * - Transaction ordering optimization: +20-30% TPS improvement
 * - Resource prediction: -25% memory, -20% CPU usage
 * - Adaptive scaling: Reduces cluster resize latency
 * - Online learning: +5% TPS per scoring model update
 */
service AIOptimizationGrpcService {
    
    // Client Streaming: Optimize transaction order using ML
    // Clients send transactions, service returns optimized order
    // Significantly improves throughput through better ordering
    rpc optimizeTransactionOrder(stream TransactionForOptimization) 
        returns (OptimizedTransactionBatch);
    
    // Unary RPC: Predict resource usage for given load
    // Forecasts CPU, memory, network requirements
    rpc predictResourceUsage(ResourceMetrics) 
        returns (ResourcePrediction);
    
    // Unary RPC: Suggest cluster scaling strategy
    // Recommends nodes to add/remove based on metrics
    rpc suggestScaling(ClusterMetrics) 
        returns (ScalingRecommendation);
    
    // Client Streaming: Update ML models
    // Continuous model improvement via training data
    rpc updateMLModel(stream ModelUpdate) 
        returns (ModelUpdateResponse);
    
    // Server Streaming: Train models on historical data
    // Long-running training with progress updates
    rpc trainOnHistoricalData(TrainingRequest) 
        returns (stream TrainingProgress);
    
    // Unary RPC: Service health check
    rpc checkHealth(Empty) 
        returns (HealthStatus);
}

// ========================================================================
// Message Types
// ========================================================================

/**
 * TransactionForOptimization: Transaction data for ML scoring
 * 
 * Used in optimizeTransactionOrder client streaming
 */
message TransactionForOptimization {
    string tx_id = 1;               // Transaction ID
    string sender = 2;              // Sender address
    string receiver = 3;            // Receiver address
    int64 value = 4;                // Transaction value
    int64 gas_limit = 5;            // Gas limit
    int64 gas_price = 6;            // Gas price
    int64 created_at = 7;           // Creation timestamp
    int32 priority = 8;             // User priority (0-10)
    bytes data = 9;                 // Transaction data/payload
    repeated string dependencies = 10;  // Dependent tx IDs
    int64 estimated_exec_time_ms = 11;  // Predicted execution time
}

/**
 * OptimizedTransactionBatch: ML-optimized transaction ordering
 * 
 * Returned from optimizeTransactionOrder
 */
message OptimizedTransactionBatch {
    repeated string optimized_tx_order = 1;  // Reordered tx IDs
    double avg_score = 2;                    // Average ML score
    double confidence = 3;                   // Confidence in ordering
    string optimization_reason = 4;          // Why this order
    int64 processing_time_ms = 5;            // Time to optimize
    int32 batch_size = 6;                    // Number of transactions
    double estimated_throughput_gain_percent = 7;  // Expected TPS improvement
}

/**
 * ResourceMetrics: Current system resource usage
 * 
 * Used to feed ML predictor
 */
message ResourceMetrics {
    double cpu_usage_percent = 1;            // Current CPU %
    double memory_usage_percent = 2;         // Current memory %
    double network_usage_mbps = 3;           // Current network Mbps
    int64 disk_io_operations = 4;            // Disk I/O ops/sec
    int32 active_transactions = 5;           // Currently processing
    int32 pending_transactions = 6;          // In mempool
    double current_tps = 7;                  // Current throughput
    int64 timestamp = 8;                     // Measurement time
}

/**
 * ResourcePrediction: ML-predicted resource requirements
 * 
 * Returned by predictResourceUsage
 */
message ResourcePrediction {
    double predicted_cpu_percent = 1;        // Predicted CPU %
    double predicted_memory_percent = 2;     // Predicted memory %
    double predicted_network_mbps = 3;       // Predicted network Mbps
    int64 peak_disk_io = 4;                  // Peak disk I/O ops/sec
    double confidence = 5;                   // Confidence level (0-1)
    string prediction_reason = 6;            // Why these predictions
    int64 prediction_horizon_seconds = 7;    // Prediction timeframe
    repeated string warning_flags = 8;       // Resource bottlenecks
}

/**
 * ClusterMetrics: Overall cluster performance metrics
 * 
 * Used to suggest scaling strategy
 */
message ClusterMetrics {
    int32 total_nodes = 1;                   // Total nodes
    int32 validator_nodes = 2;               // Validators
    int32 business_nodes = 3;                // Business nodes
    int32 slim_nodes = 4;                    // Slim nodes
    double avg_cpu_percent = 5;              // Average CPU %
    double avg_memory_percent = 6;           // Average memory %
    double network_latency_ms = 7;           // Inter-node latency
    double current_tps = 8;                  // Current platform TPS
    double target_tps = 9;                   // Target TPS
    int64 timestamp = 10;                    // Measurement time
}

/**
 * ScalingRecommendation: Recommended cluster scaling
 * 
 * Returned by suggestScaling
 */
message ScalingRecommendation {
    int32 add_validator_nodes = 1;           // Add validators
    int32 add_business_nodes = 2;            // Add business nodes
    int32 add_slim_nodes = 3;                // Add slim nodes
    int32 remove_nodes = 4;                  // Nodes to remove
    string scaling_strategy = 5;             // HORIZONTAL, VERTICAL, or HYBRID
    int64 estimated_improvement_tps = 6;     // Expected TPS gain
    int64 estimated_time_minutes = 7;        // Time to scale
    double confidence = 8;                   // Confidence level
    string reasoning = 9;                    // Scaling rationale
}

/**
 * ModelUpdate: Update to ML models
 * 
 * Sent in updateMLModel client streaming
 */
message ModelUpdate {
    string model_name = 1;                   // Model identifier
    int32 model_version = 2;                 // Version number
    bytes model_data = 3;                    // Serialized model weights
    int64 training_samples = 4;              // Samples used
    double model_accuracy = 5;               // Reported accuracy
    int64 timestamp = 6;                     // Update timestamp
}

/**
 * ModelUpdateResponse: Confirmation of model update
 * 
 * Returned from updateMLModel
 */
message ModelUpdateResponse {
    string model_name = 1;                   // Updated model
    bool accepted = 2;                       // Update accepted
    string status = 3;                       // Status message
    double new_accuracy = 4;                 // New model accuracy
    int64 update_timestamp = 5;              // When applied
}

/**
 * TrainingRequest: Request to train on historical data
 * 
 * Used to improve ML models offline
 */
message TrainingRequest {
    string model_name = 1;                   // Model to train
    int64 from_block = 2;                    // Start block number
    int64 to_block = 3;                      // End block number
    int32 training_epochs = 4;               // Number of epochs
    double learning_rate = 5;                // Learning rate
    int32 batch_size = 6;                    // Training batch size
    string training_objective = 7;           // What to optimize for
}

/**
 * TrainingProgress: Progress update during training
 * 
 * Sent in server streaming from trainOnHistoricalData
 */
message TrainingProgress {
    string model_name = 1;                   // Model being trained
    int32 current_epoch = 2;                 // Current epoch
    int32 total_epochs = 3;                  // Total epochs
    double current_loss = 4;                 // Current loss value
    double current_accuracy = 5;             // Current accuracy
    int32 samples_processed = 6;             // Samples trained
    string estimated_remaining = 7;          // ETA
    double progress_percent = 8;             // % complete
    string message = 9;                      // Status message
}

// ========================================================================
// Enums
// ========================================================================

/**
 * ScalingStrategy: Recommended scaling approach
 */
enum ScalingStrategy {
    SCALING_STRATEGY_UNKNOWN = 0;    // Unknown
    SCALING_STRATEGY_HORIZONTAL = 1; // Add nodes
    SCALING_STRATEGY_VERTICAL = 2;   // Increase node resources
    SCALING_STRATEGY_HYBRID = 3;     // Combined approach
    SCALING_STRATEGY_NONE = 4;       // No scaling needed
}
