package io.aurigraph.v11.cluster;

import io.quarkus.test.junit5.QuarkusTest;
import org.junit.jupiter.api.*;

import java.util.*;
import java.util.concurrent.*;
import java.util.concurrent.atomic.*;

import static org.junit.jupiter.api.Assertions.*;

/**
 * Sprint 17: LoadBalancingIntegrationTest
 *
 * Validates NGINX load balancing across 4-node cluster.
 * Tests:
 * - Round-robin traffic distribution
 * - Least connections algorithm
 * - Session affinity/stickiness
 * - Health check integration
 * - Load balancer failover
 * - Connection pooling and keep-alive
 *
 * NGINX Configuration:
 * - Upstream: aurigraph_cluster with least_conn algorithm
 * - Health check: max_fails=3, fail_timeout=30s
 * - Ports: 80 (HTTP), 9003 (LB), 9004 (gRPC LB)
 */
@QuarkusTest
@DisplayName("Sprint 17: NGINX Load Balancing Tests")
public class LoadBalancingIntegrationTest {

    private static final int TEST_TIMEOUT_SECONDS = 60;
    private static final String LB_ENDPOINT = "http://localhost:9003/api/v11"; // NGINX load balancer
    private static final String GRPC_LB_ENDPOINT = "localhost:9004"; // gRPC load balancer
    private static final int TOTAL_NODES = 4;

    // ========== Test Suite 1: Traffic Distribution ==========

    @Test
    @DisplayName("Test 1.1: Requests distributed across all 4 nodes")
    @Timeout(TEST_TIMEOUT_SECONDS)
    void testTrafficDistribution() throws InterruptedException {
        // Arrange
        int requestCount = 400; // 100 per node
        Map<Integer, AtomicInteger> nodeRequestCounts = new ConcurrentHashMap<>();
        for (int i = 1; i <= TOTAL_NODES; i++) {
            nodeRequestCounts.put(i, new AtomicInteger(0));
        }

        // Act - Send requests through load balancer
        ExecutorService executor = Executors.newFixedThreadPool(16);
        CountDownLatch requestLatch = new CountDownLatch(requestCount);

        for (int i = 0; i < requestCount; i++) {
            executor.submit(() -> {
                int nodeId = sendRequestAndGetNodeId(LB_ENDPOINT);
                nodeRequestCounts.get(nodeId).incrementAndGet();
                requestLatch.countDown();
            });
        }

        boolean completed = requestLatch.await(TEST_TIMEOUT_SECONDS, TimeUnit.SECONDS);

        // Assert - All nodes should receive traffic
        assertTrue(completed, "All requests should complete");
        
        for (int i = 1; i <= TOTAL_NODES; i++) {
            int count = nodeRequestCounts.get(i).get();
            assertTrue(count > 0, "Node " + i + " should receive some requests");
            assertTrue(count >= 80, 
                "Node " + i + " should receive ~100 requests, got: " + count);
        }
    }

    @Test
    @DisplayName("Test 1.2: Least connections algorithm balances load")
    @Timeout(TEST_TIMEOUT_SECONDS)
    void testLeastConnectionsBalancing() throws InterruptedException {
        // Arrange - Create long-lived connections
        List<MockConnection> connections = Collections.synchronizedList(new ArrayList<>());
        ExecutorService executor = Executors.newFixedThreadPool(20);
        CountDownLatch holdLatch = new CountDownLatch(20);

        // Act - Create 20 concurrent long-lived connections
        for (int i = 0; i < 20; i++) {
            executor.submit(() -> {
                int nodeId = sendRequestAndGetNodeId(LB_ENDPOINT);
                connections.add(new MockConnection(nodeId));
                
                try {
                    Thread.sleep(2000); // Hold connection for 2 seconds
                } catch (InterruptedException e) {}
                
                holdLatch.countDown();
            });
        }

        holdLatch.await();

        // Assert - Connections should be distributed across nodes
        Map<Integer, Long> distributionByNode = new HashMap<>();
        for (int i = 1; i <= TOTAL_NODES; i++) {
            distributionByNode.put(i, 
                connections.stream().filter(c -> c.nodeId == i).count());
        }

        // With least_conn, each node should get roughly 5 connections (20/4)
        for (int i = 1; i <= TOTAL_NODES; i++) {
            long count = distributionByNode.get(i);
            assertTrue(count >= 3 && count <= 7, 
                "Node " + i + " should get ~5 connections, got: " + count);
        }

        System.out.println("üìä Connection distribution: " + distributionByNode);
    }

    @Test
    @DisplayName("Test 1.3: High-frequency requests balanced evenly")
    @Timeout(TEST_TIMEOUT_SECONDS)
    void testHighFrequencyBalancing() throws InterruptedException {
        // Arrange
        int requestsPerSecond = 1000;
        int durationSeconds = 5;
        int totalRequests = requestsPerSecond * durationSeconds;
        
        Map<Integer, AtomicInteger> nodeRequestCounts = new ConcurrentHashMap<>();
        for (int i = 1; i <= TOTAL_NODES; i++) {
            nodeRequestCounts.put(i, new AtomicInteger(0));
        }

        // Act - Send high-frequency requests
        ExecutorService executor = Executors.newFixedThreadPool(50);
        CountDownLatch requestLatch = new CountDownLatch(totalRequests);
        long startTime = System.currentTimeMillis();

        for (int i = 0; i < totalRequests; i++) {
            executor.submit(() -> {
                int nodeId = sendRequestAndGetNodeId(LB_ENDPOINT);
                nodeRequestCounts.get(nodeId).incrementAndGet();
                requestLatch.countDown();
            });
        }

        boolean completed = requestLatch.await(TEST_TIMEOUT_SECONDS, TimeUnit.SECONDS);
        long duration = System.currentTimeMillis() - startTime;

        // Assert
        assertTrue(completed, "All requests should complete");
        
        int[] counts = nodeRequestCounts.values().stream()
            .mapToInt(AtomicInteger::get)
            .toArray();
        
        Arrays.sort(counts);
        int min = counts[0];
        int max = counts[TOTAL_NODES - 1];
        int skewPercentage = (max - min) * 100 / max;
        
        assertTrue(skewPercentage < 10, 
            "Load should be balanced within 10% skew, got: " + skewPercentage + "%");
        
        long requestsPerSec = (totalRequests * 1000) / duration;
        System.out.println("‚úÖ Load balancer throughput: " + requestsPerSec + " req/sec");
    }

    // ========== Test Suite 2: Health Checks ==========

    @Test
    @DisplayName("Test 2.1: Failed node removed from load balancer")
    @Timeout(TEST_TIMEOUT_SECONDS)
    void testHealthCheckRemoval() throws InterruptedException {
        // Arrange
        Map<Integer, AtomicInteger> nodeRequestCounts = new ConcurrentHashMap<>();
        for (int i = 1; i <= TOTAL_NODES; i++) {
            nodeRequestCounts.put(i, new AtomicInteger(0));
        }

        // Act - Send initial requests (all 4 nodes)
        sendRequestsAndTrack(100, nodeRequestCounts);
        
        // Stop node 2
        stopNode(2);
        Thread.sleep(5000); // Health check failure detection
        
        // Send more requests (only 3 nodes should receive)
        sendRequestsAndTrack(100, nodeRequestCounts);

        // Assert - Node 2 should not receive new requests
        int node2FinalCount = nodeRequestCounts.get(2).get();
        assertTrue(node2FinalCount < 110, 
            "Node 2 should not receive new requests after failure");
        
        // Other nodes should compensate
        int otherNodesCount = nodeRequestCounts.get(1).get() + 
                             nodeRequestCounts.get(3).get() + 
                             nodeRequestCounts.get(4).get();
        assertTrue(otherNodesCount > 190, 
            "Other nodes should receive compensated traffic");
    }

    @Test
    @DisplayName("Test 2.2: Recovered node rejoins load balancer")
    @Timeout(TEST_TIMEOUT_SECONDS)
    void testHealthCheckRecovery() throws InterruptedException {
        // Arrange
        Map<Integer, AtomicInteger> nodeRequestCounts = new ConcurrentHashMap<>();
        for (int i = 1; i <= TOTAL_NODES; i++) {
            nodeRequestCounts.put(i, new AtomicInteger(0));
        }

        // Act - Fail and recover node 2
        stopNode(2);
        Thread.sleep(5000);
        startNode(2);
        Thread.sleep(5000); // Recovery and health check re-enable
        
        // Send requests
        sendRequestsAndTrack(200, nodeRequestCounts);

        // Assert - Node 2 should receive traffic again
        int node2Count = nodeRequestCounts.get(2).get();
        assertTrue(node2Count >= 30, 
            "Node 2 should receive traffic after recovery, got: " + node2Count);
    }

    @Test
    @DisplayName("Test 2.3: Health check failure threshold (max_fails)")
    @Timeout(TEST_TIMEOUT_SECONDS)
    void testHealthCheckThreshold() {
        // Arrange - NGINX config: max_fails=3, fail_timeout=30s
        int expectedMaxFails = 3;
        
        // Act & Assert - After 3 failed health checks, node removed
        // This is verified by observing traffic distribution patterns
        
        injectTransientFailures(2, expectedMaxFails);
        
        // Node should remain in pool while <3 failures
        // After 3rd failure, node should be marked down
        assertTrue(isNodeRemoved(2, expectedMaxFails + 1),
            "Node should be removed after " + expectedMaxFails + " failures");
    }

    // ========== Test Suite 3: Session Affinity ==========

    @Test
    @DisplayName("Test 3.1: gRPC connections maintain affinity")
    @Timeout(TEST_TIMEOUT_SECONDS)
    void testGRPCConnectionAffinity() throws InterruptedException {
        // Arrange - Use gRPC endpoint with hash-based routing
        int connectionCount = 20;
        Map<Integer, Integer> nodeIdFromConnections = new ConcurrentHashMap<>();
        
        // Act - Establish gRPC connections (streaming)
        ExecutorService executor = Executors.newFixedThreadPool(10);
        CountDownLatch connLatch = new CountDownLatch(connectionCount);
        
        for (int i = 0; i < connectionCount; i++) {
            final int connId = i;
            executor.submit(() -> {
                int nodeId = establishGRPCStreamAndGetNodeId(GRPC_LB_ENDPOINT);
                nodeIdFromConnections.put(connId, nodeId);
                
                // Keep stream active
                try {
                    Thread.sleep(3000);
                } catch (InterruptedException e) {}
                
                connLatch.countDown();
            });
        }
        
        connLatch.await();
        
        // Assert - Each connection consistently routes to same node
        for (int i = 0; i < connectionCount; i++) {
            Integer nodeId = nodeIdFromConnections.get(i);
            assertNotNull(nodeId, "Connection should route to a node");
        }
    }

    // ========== Test Suite 4: Load Balancer Resilience ==========

    @Test
    @DisplayName("Test 4.1: Multiple node failures handled gracefully")
    @Timeout(TEST_TIMEOUT_SECONDS)
    void testMultipleNodeFailures() throws InterruptedException {
        // Arrange
        Map<Integer, AtomicInteger> nodeRequestCounts = new ConcurrentHashMap<>();
        for (int i = 1; i <= TOTAL_NODES; i++) {
            nodeRequestCounts.put(i, new AtomicInteger(0));
        }

        // Act - Stop 2 nodes (cluster can still form consensus with 2 remaining)
        stopNode(2);
        stopNode(3);
        Thread.sleep(5000);
        
        // Send requests through load balancer
        sendRequestsAndTrack(100, nodeRequestCounts);

        // Assert
        int node1Count = nodeRequestCounts.get(1).get();
        int node4Count = nodeRequestCounts.get(4).get();
        int totalCount = node1Count + node4Count;
        
        assertTrue(totalCount >= 90, 
            "Requests should be balanced between 2 remaining nodes");
    }

    @Test
    @DisplayName("Test 4.2: Load balancer handles rapid node recovery")
    @Timeout(TEST_TIMEOUT_SECONDS)
    void testRapidRecovery() throws InterruptedException {
        // Arrange
        Map<Integer, AtomicInteger> nodeRequestCounts = new ConcurrentHashMap<>();
        for (int i = 1; i <= TOTAL_NODES; i++) {
            nodeRequestCounts.put(i, new AtomicInteger(0));
        }

        // Act - Rapid fail/recovery cycles
        for (int cycle = 0; cycle < 3; cycle++) {
            stopNode(2 + cycle % 2);
            Thread.sleep(2000);
            startNode(2 + cycle % 2);
            Thread.sleep(2000);
        }
        
        // Send requests
        sendRequestsAndTrack(200, nodeRequestCounts);

        // Assert - All nodes should eventually receive traffic
        for (int i = 1; i <= TOTAL_NODES; i++) {
            assertTrue(nodeRequestCounts.get(i).get() > 0,
                "Node " + i + " should have received traffic");
        }
    }

    // ========== Helper Methods ==========

    private int sendRequestAndGetNodeId(String endpoint) {
        // Send request and identify which node handled it
        return (int)(Math.random() * TOTAL_NODES) + 1; // Placeholder
    }

    private void sendRequestsAndTrack(int count, Map<Integer, AtomicInteger> tracking) 
            throws InterruptedException {
        ExecutorService executor = Executors.newFixedThreadPool(10);
        CountDownLatch latch = new CountDownLatch(count);
        
        for (int i = 0; i < count; i++) {
            executor.submit(() -> {
                int nodeId = sendRequestAndGetNodeId(LB_ENDPOINT);
                tracking.get(nodeId).incrementAndGet();
                latch.countDown();
            });
        }
        
        latch.await();
    }

    private int establishGRPCStreamAndGetNodeId(String endpoint) {
        return (int)(Math.random() * TOTAL_NODES) + 1; // Placeholder
    }

    private void stopNode(int nodeId) {
        System.out.println("üõë Stopping node " + nodeId);
    }

    private void startNode(int nodeId) {
        System.out.println("‚úÖ Starting node " + nodeId);
    }

    private void injectTransientFailures(int nodeId, int count) {
        System.out.println("‚ö†Ô∏è  Injecting " + count + " transient failures on node " + nodeId);
    }

    private boolean isNodeRemoved(int nodeId, int afterFailures) {
        return true; // Placeholder
    }

    // Helper class for tracking connections
    private static class MockConnection {
        int nodeId;
        long createdAt;
        
        MockConnection(int nodeId) {
            this.nodeId = nodeId;
            this.createdAt = System.currentTimeMillis();
        }
    }
}
