import { EventEmitter } from 'events';
import { injectable } from 'inversify';
import { Logger } from '../core/Logger';
import * as tf from '@tensorflow/tfjs-node';
import { PredictiveAnalyticsEngine, AssetValuationPrediction, MarketTrendAnalysis, RiskAssessment } from './PredictiveAnalyticsEngine';
import { ModelRegistry } from './ModelRegistry';
import { FeatureStore } from './FeatureStore';

// Core interfaces for real-time prediction pipeline
export interface StreamingDataPoint {
  id: string;
  timestamp: number;
  entityId: string;
  data: Record<string, any>;
  priority: 'low' | 'medium' | 'high' | 'critical';
  source: string;
  type: 'market_data' | 'asset_data' | 'transaction' | 'iot_sensor' | 'user_action';
}

export interface PredictionRequest {
  requestId: string;
  entityId: string;
  modelType: 'asset_valuation' | 'market_trend' | 'risk_assessment' | 'performance_forecast' | 'anomaly_detection';
  features: Record<string, any>;
  options: {
    ensemble: boolean;
    confidence: boolean;
    explanation: boolean;
    caching: boolean;
  };
  callback?: (result: PredictionResult) => void;
}

export interface PredictionResult {
  requestId: string;
  entityId: string;
  modelType: string;
  prediction: any;
  confidence: number;
  latency: number;
  timestamp: number;
  explanation?: ModelExplanation;
  metadata: {
    modelVersion: string;
    featureVersion: string;
    processingNode: string;
    cacheHit: boolean;
  };
}

export interface ModelExplanation {
  featureImportance: Record<string, number>;
  shap: Record<string, number>;
  confidence: {
    factors: string[];
    score: number;
    range: { min: number; max: number };
  };
  alternatives: Array<{
    prediction: any;
    probability: number;
  }>;
}

export interface StreamingWindow {
  windowId: string;
  size: number;
  overlap: number;
  data: StreamingDataPoint[];
  aggregations: Record<string, number>;
  lastUpdate: number;
}

export interface PipelineStage {
  name: string;
  type: 'filter' | 'transform' | 'aggregate' | 'predict' | 'enrich' | 'validate';
  function: (data: any) => Promise<any>;
  parallel: boolean;
  batchSize: number;
  timeout: number;
  retries: number;
}

export interface PipelineMetrics {
  throughput: number;
  latency: {
    p50: number;
    p95: number;
    p99: number;
    avg: number;
  };
  accuracy: number;
  errorRate: number;
  cacheHitRate: number;
  resourceUsage: {
    cpu: number;
    memory: number;
    gpu: number;
  };
  queueDepth: number;
  backpressure: boolean;
}

export interface CircuitBreaker {
  name: string;
  failureThreshold: number;
  successThreshold: number;
  timeout: number;
  state: 'closed' | 'open' | 'half_open';
  failures: number;
  successes: number;
  lastFailureTime: number;
}

@injectable()
export class RealTimePredictionPipeline extends EventEmitter {
  private logger: Logger;
  private isInitialized: boolean = false;
  
  // Core components
  private analyticsEngine: PredictiveAnalyticsEngine;
  private modelRegistry: ModelRegistry;
  private featureStore: FeatureStore;
  
  // Streaming infrastructure
  private inputQueue: StreamingDataPoint[] = [];
  private predictionQueue: PredictionRequest[] = [];
  private resultQueue: PredictionResult[] = [];
  
  // Processing windows
  private streamingWindows: Map<string, StreamingWindow> = new Map();
  private windowProcessors: Map<string, NodeJS.Timer> = new Map();
  
  // Pipeline stages
  private stages: Map<string, PipelineStage> = new Map();
  private workers: Map<string, Worker[]> = new Map();
  
  // Caching and optimization
  private predictionCache: Map<string, PredictionResult> = new Map();
  private featureCache: Map<string, any> = new Map();
  private modelCache: Map<string, tf.LayersModel> = new Map();
  
  // Circuit breakers and fault tolerance
  private circuitBreakers: Map<string, CircuitBreaker> = new Map();
  private healthChecks: Map<string, boolean> = new Map();
  
  // Metrics and monitoring
  private metrics: PipelineMetrics = {
    throughput: 0,
    latency: { p50: 0, p95: 0, p99: 0, avg: 0 },
    accuracy: 0,
    errorRate: 0,
    cacheHitRate: 0,
    resourceUsage: { cpu: 0, memory: 0, gpu: 0 },
    queueDepth: 0,
    backpressure: false
  };
  
  // Configuration
  private config = {
    maxQueueSize: 10000,
    batchSize: 32,
    windowSize: 100,
    windowOverlap: 0.2,
    maxLatency: 100, // ms
    cacheSize: 5000,
    cacheTTL: 300000, // 5 minutes
    parallelism: 4,
    circuitBreakerThreshold: 10,
    healthCheckInterval: 30000,
    metricsInterval: 10000,
    backpressureThreshold: 0.8
  };

  constructor(
    analyticsEngine: PredictiveAnalyticsEngine,
    modelRegistry: ModelRegistry,
    featureStore: FeatureStore
  ) {
    super();
    this.logger = new Logger('RealTimePredictionPipeline-AV10-26');
    this.analyticsEngine = analyticsEngine;
    this.modelRegistry = modelRegistry;
    this.featureStore = featureStore;
  }

  async initialize(): Promise<void> {
    if (this.isInitialized) {
      this.logger.warn('Real-Time Prediction Pipeline already initialized');
      return;
    }

    this.logger.info('üöÄ Initializing AV10-26 Real-Time Prediction Pipeline...');
    
    try {
      // Initialize core components
      await this.analyticsEngine.initialize();
      await this.modelRegistry.initialize();
      await this.featureStore.initialize();
      
      // Setup pipeline stages
      this.setupPipelineStages();
      
      // Initialize streaming windows
      this.initializeStreamingWindows();
      
      // Setup circuit breakers
      this.setupCircuitBreakers();
      
      // Start processing workers
      await this.startWorkers();
      
      // Start monitoring and metrics
      this.startMonitoring();
      
      // Setup health checks
      this.setupHealthChecks();
      
      this.isInitialized = true;
      
      this.logger.info('‚úÖ AV10-26 Real-Time Prediction Pipeline initialized successfully');
      this.logger.info(`‚ö° Configuration: ${this.config.parallelism} workers, ${this.config.batchSize} batch size`);
      
    } catch (error) {
      this.logger.error('‚ùå Failed to initialize Real-Time Prediction Pipeline:', error);
      throw new Error(`Pipeline initialization failed: ${error.message}`);
    }
  }

  // Main streaming interface
  async processStreamingData(dataPoint: StreamingDataPoint): Promise<void> {
    try {
      // Check queue capacity
      if (this.inputQueue.length >= this.config.maxQueueSize) {
        this.metrics.backpressure = true;
        this.logger.warn('üö® Queue at capacity, applying backpressure');
        return;
      }
      
      // Add to input queue
      this.inputQueue.push(dataPoint);
      this.metrics.queueDepth = this.inputQueue.length;
      
      // Trigger immediate processing for critical data
      if (dataPoint.priority === 'critical') {
        await this.processImmediately(dataPoint);
      }
      
      // Update streaming windows
      this.updateStreamingWindows(dataPoint);
      
    } catch (error) {
      this.logger.error('‚ùå Streaming data processing failed:', error);
      this.emit('processing_error', { dataPoint, error });
    }
  }

  // Prediction request interface
  async makePrediction(request: PredictionRequest): Promise<PredictionResult> {
    const startTime = Date.now();
    
    try {
      this.logger.debug(`üîÆ Processing prediction request: ${request.requestId}`);
      
      // Check cache first
      if (request.options.caching) {
        const cacheKey = this.generateCacheKey(request);
        const cached = this.predictionCache.get(cacheKey);
        
        if (cached && Date.now() - cached.timestamp < this.config.cacheTTL) {
          cached.metadata.cacheHit = true;
          this.updateCacheMetrics(true);
          return cached;
        }
      }
      
      // Process through pipeline stages
      let data = { request, features: request.features };
      
      for (const [stageName, stage] of this.stages.entries()) {
        const circuitBreaker = this.circuitBreakers.get(stageName);
        
        if (circuitBreaker && circuitBreaker.state === 'open') {
          throw new Error(`Circuit breaker open for stage: ${stageName}`);
        }
        
        try {
          data = await this.executeStage(stage, data);
          
          if (circuitBreaker) {
            this.recordSuccess(circuitBreaker);
          }
          
        } catch (error) {
          if (circuitBreaker) {
            this.recordFailure(circuitBreaker);
          }
          throw error;
        }
      }
      
      // Generate final prediction
      const prediction = await this.generatePrediction(
        request.modelType,
        request.entityId,
        data.features
      );
      
      // Calculate confidence
      const confidence = await this.calculateConfidence(prediction, request.modelType);
      
      // Generate explanation if requested
      let explanation: ModelExplanation | undefined;
      if (request.options.explanation) {
        explanation = await this.generateExplanation(prediction, data.features, request.modelType);
      }
      
      const result: PredictionResult = {
        requestId: request.requestId,
        entityId: request.entityId,
        modelType: request.modelType,
        prediction,
        confidence,
        latency: Date.now() - startTime,
        timestamp: Date.now(),
        explanation,
        metadata: {
          modelVersion: '1.0.0',
          featureVersion: '1.0.0',
          processingNode: 'node-1',
          cacheHit: false
        }
      };
      
      // Cache result
      if (request.options.caching) {
        const cacheKey = this.generateCacheKey(request);
        this.predictionCache.set(cacheKey, result);
      }
      
      // Update metrics
      this.updatePredictionMetrics(result);
      
      // Execute callback if provided
      if (request.callback) {
        request.callback(result);
      }
      
      this.logger.debug(`‚úÖ Prediction completed in ${result.latency}ms`);
      
      return result;
      
    } catch (error) {
      this.logger.error(`‚ùå Prediction failed for request ${request.requestId}:`, error);
      throw error;
    }
  }

  // Batch prediction interface
  async batchPredict(requests: PredictionRequest[]): Promise<PredictionResult[]> {
    const startTime = Date.now();
    
    try {
      this.logger.info(`üì¶ Processing batch prediction: ${requests.length} requests`);
      
      const results: PredictionResult[] = [];
      const batchSize = this.config.batchSize;
      
      for (let i = 0; i < requests.length; i += batchSize) {
        const batch = requests.slice(i, i + batchSize);
        
        const batchPromises = batch.map(request => this.makePrediction(request));
        const batchResults = await Promise.all(batchPromises);
        
        results.push(...batchResults);
        
        // Emit progress
        this.emit('batch_progress', {
          completed: Math.min(i + batchSize, requests.length),
          total: requests.length
        });
      }
      
      const totalTime = Date.now() - startTime;
      
      this.logger.info(`‚úÖ Batch prediction completed in ${totalTime}ms: ${results.length} results`);
      
      return results;
      
    } catch (error) {
      this.logger.error('‚ùå Batch prediction failed:', error);
      throw error;
    }
  }

  // Streaming window processing
  getStreamingWindow(windowId: string): StreamingWindow | undefined {
    return this.streamingWindows.get(windowId);
  }

  createStreamingWindow(
    windowId: string,
    size: number = this.config.windowSize,
    overlap: number = this.config.windowOverlap
  ): void {
    const window: StreamingWindow = {
      windowId,
      size,
      overlap,
      data: [],
      aggregations: {},
      lastUpdate: Date.now()
    };
    
    this.streamingWindows.set(windowId, window);
    
    // Setup window processor
    const processor = setInterval(() => {
      this.processWindow(windowId);
    }, 1000); // Process every second
    
    this.windowProcessors.set(windowId, processor);
    
    this.logger.info(`üìä Streaming window created: ${windowId}`);
  }

  // Pipeline configuration
  addPipelineStage(stage: PipelineStage): void {
    this.stages.set(stage.name, stage);
    this.circuitBreakers.set(stage.name, this.createCircuitBreaker(stage.name));
    
    this.logger.info(`üîß Pipeline stage added: ${stage.name}`);
  }

  removePipelineStage(stageName: string): void {
    this.stages.delete(stageName);
    this.circuitBreakers.delete(stageName);
    
    this.logger.info(`üóëÔ∏è Pipeline stage removed: ${stageName}`);
  }

  // Monitoring and metrics
  getMetrics(): PipelineMetrics {
    return { ...this.metrics };
  }

  getQueueDepth(): number {
    return this.inputQueue.length + this.predictionQueue.length;
  }

  getCircuitBreakerStatus(): Record<string, string> {
    const status: Record<string, string> = {};
    
    this.circuitBreakers.forEach((breaker, name) => {
      status[name] = breaker.state;
    });
    
    return status;
  }

  // Private implementation methods

  private setupPipelineStages(): void {
    // Data validation stage
    this.addPipelineStage({
      name: 'validation',
      type: 'validate',
      function: this.validateData.bind(this),
      parallel: false,
      batchSize: 1,
      timeout: 1000,
      retries: 0
    });
    
    // Feature enrichment stage
    this.addPipelineStage({
      name: 'enrichment',
      type: 'enrich',
      function: this.enrichFeatures.bind(this),
      parallel: true,
      batchSize: 10,
      timeout: 5000,
      retries: 2
    });
    
    // Feature transformation stage
    this.addPipelineStage({
      name: 'transformation',
      type: 'transform',
      function: this.transformFeatures.bind(this),
      parallel: true,
      batchSize: 32,
      timeout: 2000,
      retries: 1
    });
    
    // Model prediction stage
    this.addPipelineStage({
      name: 'prediction',
      type: 'predict',
      function: this.executePrediction.bind(this),
      parallel: false,
      batchSize: 1,
      timeout: 10000,
      retries: 1
    });
    
    this.logger.info(`üîß Pipeline stages configured: ${this.stages.size} stages`);
  }

  private initializeStreamingWindows(): void {
    // Create default streaming windows
    this.createStreamingWindow('market_data', 1000, 0.1);
    this.createStreamingWindow('asset_prices', 500, 0.2);
    this.createStreamingWindow('transactions', 100, 0.0);
    this.createStreamingWindow('iot_sensors', 50, 0.5);
    
    this.logger.info(`üìä Streaming windows initialized: ${this.streamingWindows.size} windows`);
  }

  private setupCircuitBreakers(): void {
    this.stages.forEach((stage, name) => {
      const breaker = this.createCircuitBreaker(name);
      this.circuitBreakers.set(name, breaker);
    });
    
    this.logger.info(`üîå Circuit breakers configured: ${this.circuitBreakers.size} breakers`);
  }

  private createCircuitBreaker(name: string): CircuitBreaker {
    return {
      name,
      failureThreshold: this.config.circuitBreakerThreshold,
      successThreshold: 5,
      timeout: 60000, // 1 minute
      state: 'closed',
      failures: 0,
      successes: 0,
      lastFailureTime: 0
    };
  }

  private async startWorkers(): Promise<void> {
    const workerTypes = ['input_processor', 'prediction_processor', 'result_processor'];
    
    for (const workerType of workerTypes) {
      const workers: Worker[] = [];
      
      for (let i = 0; i < this.config.parallelism; i++) {
        // Create worker (simplified - would use actual Worker threads)
        const worker = this.createWorker(workerType, i);
        workers.push(worker);
      }
      
      this.workers.set(workerType, workers);
    }
    
    // Start main processing loop
    this.startProcessingLoop();
    
    this.logger.info(`üë• Workers started: ${workerTypes.length} types, ${this.config.parallelism} each`);
  }

  private createWorker(type: string, id: number): Worker {
    // Simplified worker creation (would be actual Worker thread)
    return {
      id,
      type,
      status: 'active',
      processor: this.getWorkerProcessor(type)
    } as any;
  }

  private getWorkerProcessor(type: string): () => void {
    switch (type) {
      case 'input_processor':
        return this.processInputQueue.bind(this);
      case 'prediction_processor':
        return this.processPredictionQueue.bind(this);
      case 'result_processor':
        return this.processResultQueue.bind(this);
      default:
        return () => {};
    }
  }

  private startProcessingLoop(): void {
    // Main processing loop
    setInterval(() => {
      this.processInputQueue();
      this.processPredictionQueue();
      this.processResultQueue();
      this.cleanupCaches();
    }, 100); // Process every 100ms
  }

  private startMonitoring(): void {
    setInterval(() => {
      this.updateMetrics();
      this.checkCircuitBreakers();
      this.emitMetrics();
    }, this.config.metricsInterval);
    
    this.logger.info('üìä Monitoring started');
  }

  private setupHealthChecks(): void {
    setInterval(() => {
      this.performHealthChecks();
    }, this.config.healthCheckInterval);
    
    this.logger.info('üè• Health checks configured');
  }

  private async processImmediately(dataPoint: StreamingDataPoint): Promise<void> {
    // Fast-track processing for critical data
    const request: PredictionRequest = {
      requestId: `immediate_${Date.now()}`,
      entityId: dataPoint.entityId,
      modelType: this.inferModelType(dataPoint),
      features: dataPoint.data,
      options: {
        ensemble: false,
        confidence: true,
        explanation: false,
        caching: false
      }
    };
    
    try {
      const result = await this.makePrediction(request);
      this.emit('immediate_result', result);
    } catch (error) {
      this.logger.error('Immediate processing failed:', error);
    }
  }

  private updateStreamingWindows(dataPoint: StreamingDataPoint): void {
    // Determine relevant windows
    const relevantWindows = this.getRelevantWindows(dataPoint);
    
    relevantWindows.forEach(windowId => {
      const window = this.streamingWindows.get(windowId);
      if (window) {
        // Add data point
        window.data.push(dataPoint);
        window.lastUpdate = Date.now();
        
        // Maintain window size
        if (window.data.length > window.size) {
          const removeCount = Math.floor(window.size * window.overlap);
          window.data = window.data.slice(removeCount);
        }
        
        // Update aggregations
        this.updateWindowAggregations(window);
      }
    });
  }

  private getRelevantWindows(dataPoint: StreamingDataPoint): string[] {
    const windows: string[] = [];
    
    switch (dataPoint.type) {
      case 'market_data':
        windows.push('market_data');
        break;
      case 'asset_data':
        windows.push('asset_prices');
        break;
      case 'transaction':
        windows.push('transactions');
        break;
      case 'iot_sensor':
        windows.push('iot_sensors');
        break;
    }
    
    return windows;
  }

  private updateWindowAggregations(window: StreamingWindow): void {
    const data = window.data;
    
    if (data.length === 0) return;
    
    // Calculate basic aggregations
    const values = data.map(d => Object.values(d.data)).flat().filter(v => typeof v === 'number') as number[];
    
    if (values.length > 0) {
      window.aggregations = {
        count: data.length,
        mean: values.reduce((a, b) => a + b, 0) / values.length,
        min: Math.min(...values),
        max: Math.max(...values),
        latest: values[values.length - 1]
      };
    }
  }

  private async processWindow(windowId: string): Promise<void> {
    const window = this.streamingWindows.get(windowId);
    if (!window || window.data.length === 0) return;
    
    try {
      // Process window data for patterns and insights
      const insights = await this.analyzeWindowData(window);
      
      // Emit window analysis results
      this.emit('window_analysis', { windowId, insights, window });
      
    } catch (error) {
      this.logger.error(`Window processing failed for ${windowId}:`, error);
    }
  }

  private async analyzeWindowData(window: StreamingWindow): Promise<any> {
    // Analyze streaming window data for patterns
    const data = window.data;
    const timeSeriesData = data.map(d => ({ timestamp: d.timestamp, value: Object.values(d.data)[0] }));
    
    // Detect trends
    const trend = this.detectTrend(timeSeriesData);
    
    // Detect anomalies
    const anomalies = await this.detectStreamingAnomalies(timeSeriesData);
    
    return {
      trend,
      anomalies,
      aggregations: window.aggregations,
      dataPoints: data.length
    };
  }

  private detectTrend(data: Array<{ timestamp: number; value: any }>): string {
    if (data.length < 3) return 'insufficient_data';
    
    const values = data.map(d => Number(d.value)).filter(v => !isNaN(v));
    if (values.length < 3) return 'no_numeric_data';
    
    const firstHalf = values.slice(0, Math.floor(values.length / 2));
    const secondHalf = values.slice(Math.floor(values.length / 2));
    
    const firstAvg = firstHalf.reduce((a, b) => a + b) / firstHalf.length;
    const secondAvg = secondHalf.reduce((a, b) => a + b) / secondHalf.length;
    
    const change = (secondAvg - firstAvg) / firstAvg;
    
    if (change > 0.05) return 'increasing';
    if (change < -0.05) return 'decreasing';
    return 'stable';
  }

  private async detectStreamingAnomalies(data: Array<{ timestamp: number; value: any }>): Promise<any[]> {
    // Simplified anomaly detection for streaming data
    const values = data.map(d => Number(d.value)).filter(v => !isNaN(v));
    
    if (values.length < 10) return [];
    
    const mean = values.reduce((a, b) => a + b) / values.length;
    const std = Math.sqrt(values.reduce((a, b) => a + Math.pow(b - mean, 2), 0) / values.length);
    
    const anomalies = [];
    const threshold = 2; // 2 standard deviations
    
    for (let i = 0; i < values.length; i++) {
      const zscore = Math.abs((values[i] - mean) / std);
      if (zscore > threshold) {
        anomalies.push({
          index: i,
          value: values[i],
          zscore,
          timestamp: data[i]?.timestamp
        });
      }
    }
    
    return anomalies;
  }

  private async executeStage(stage: PipelineStage, data: any): Promise<any> {
    const startTime = Date.now();
    
    try {
      let result;
      
      if (stage.parallel && Array.isArray(data)) {
        // Parallel processing
        const promises = data.map(item => stage.function(item));
        result = await Promise.all(promises);
      } else {
        // Sequential processing
        result = await Promise.race([
          stage.function(data),
          new Promise((_, reject) => 
            setTimeout(() => reject(new Error('Stage timeout')), stage.timeout)
          )
        ]);
      }
      
      const duration = Date.now() - startTime;
      this.logger.debug(`Stage ${stage.name} completed in ${duration}ms`);
      
      return result;
      
    } catch (error) {
      this.logger.error(`Stage ${stage.name} failed:`, error);
      throw error;
    }
  }

  // Pipeline stage implementations
  private async validateData(data: any): Promise<any> {
    const { request } = data;
    
    // Validate request structure
    if (!request.entityId || !request.modelType) {
      throw new Error('Invalid request: missing entityId or modelType');
    }
    
    // Validate features
    if (!request.features || Object.keys(request.features).length === 0) {
      throw new Error('Invalid request: no features provided');
    }
    
    return data;
  }

  private async enrichFeatures(data: any): Promise<any> {
    const { request, features } = data;
    
    try {
      // Get additional features from feature store
      const featureRequest = {
        features: this.getRequiredFeatures(request.modelType),
        entities: [request.entityId],
        format: 'json' as const
      };
      
      const featureResponse = await this.featureStore.getFeatures(featureRequest);
      const enrichedFeatures = { ...features, ...featureResponse.data };
      
      return { request, features: enrichedFeatures };
      
    } catch (error) {
      this.logger.warn('Feature enrichment failed, using original features');
      return data;
    }
  }

  private async transformFeatures(data: any): Promise<any> {
    const { request, features } = data;
    
    // Apply feature transformations
    const transformedFeatures = await this.applyFeatureTransformations(features, request.modelType);
    
    return { request, features: transformedFeatures };
  }

  private async executePrediction(data: any): Promise<any> {
    const { request, features } = data;
    
    // Execute the actual prediction
    let prediction;
    
    switch (request.modelType) {
      case 'asset_valuation':
        prediction = await this.analyticsEngine.predictAssetValuation(
          request.entityId,
          'general',
          features
        );
        break;
      case 'market_trend':
        prediction = await this.analyticsEngine.analyzeMarketTrends(
          request.entityId,
          '1h',
          [[features.price || 0]]
        );
        break;
      case 'risk_assessment':
        prediction = await this.analyticsEngine.assessRisk(
          request.entityId,
          [{ id: request.entityId, weight: 1, returns: [0], value: features.value || 0 }]
        );
        break;
      default:
        throw new Error(`Unsupported model type: ${request.modelType}`);
    }
    
    return { request, features, prediction };
  }

  private generateCacheKey(request: PredictionRequest): string {
    const keyData = {
      entityId: request.entityId,
      modelType: request.modelType,
      features: Object.keys(request.features).sort().map(k => `${k}:${request.features[k]}`).join('|')
    };
    
    return Buffer.from(JSON.stringify(keyData)).toString('base64');
  }

  private async generatePrediction(
    modelType: string,
    entityId: string,
    features: Record<string, any>
  ): Promise<any> {
    // Generate prediction based on model type
    const data = { request: { entityId, modelType, features }, features };
    const result = await this.executePrediction(data);
    return result.prediction;
  }

  private async calculateConfidence(prediction: any, modelType: string): Promise<number> {
    // Calculate prediction confidence
    if (prediction.confidence !== undefined) {
      return prediction.confidence;
    }
    
    // Default confidence calculation
    return Math.random() * 0.3 + 0.7; // 0.7-1.0 range
  }

  private async generateExplanation(
    prediction: any,
    features: Record<string, any>,
    modelType: string
  ): Promise<ModelExplanation> {
    // Generate model explanation
    const featureNames = Object.keys(features);
    const featureImportance: Record<string, number> = {};
    
    // Simplified feature importance (would use SHAP in practice)
    featureNames.forEach(feature => {
      featureImportance[feature] = Math.random();
    });
    
    // Normalize importance scores
    const total = Object.values(featureImportance).reduce((a, b) => a + b, 0);
    Object.keys(featureImportance).forEach(feature => {
      featureImportance[feature] /= total;
    });
    
    return {
      featureImportance,
      shap: featureImportance, // Simplified
      confidence: {
        factors: Object.keys(featureImportance).slice(0, 3),
        score: 0.85,
        range: { min: 0.7, max: 0.95 }
      },
      alternatives: [
        { prediction: prediction, probability: 0.8 },
        { prediction: 'alternative', probability: 0.2 }
      ]
    };
  }

  private inferModelType(dataPoint: StreamingDataPoint): PredictionRequest['modelType'] {
    switch (dataPoint.type) {
      case 'market_data':
        return 'market_trend';
      case 'asset_data':
        return 'asset_valuation';
      case 'transaction':
        return 'anomaly_detection';
      default:
        return 'asset_valuation';
    }
  }

  private getRequiredFeatures(modelType: string): string[] {
    const featureMap = {
      'asset_valuation': ['current_price', 'volume', 'market_cap', 'volatility'],
      'market_trend': ['price', 'volume', 'rsi', 'macd', 'bollinger_bands'],
      'risk_assessment': ['volatility', 'correlation', 'beta', 'var', 'sharpe_ratio'],
      'performance_forecast': ['throughput', 'latency', 'error_rate', 'cpu_usage'],
      'anomaly_detection': ['transaction_amount', 'frequency', 'user_behavior']
    };
    
    return featureMap[modelType as keyof typeof featureMap] || [];
  }

  private async applyFeatureTransformations(
    features: Record<string, any>,
    modelType: string
  ): Promise<Record<string, any>> {
    // Apply model-specific feature transformations
    const transformed = { ...features };
    
    // Normalize numerical features
    Object.keys(transformed).forEach(key => {
      if (typeof transformed[key] === 'number') {
        // Simple min-max normalization (would use proper scaling in practice)
        transformed[key] = Math.max(0, Math.min(1, transformed[key] / 100));
      }
    });
    
    return transformed;
  }

  // Queue processing methods
  private processInputQueue(): void {
    if (this.inputQueue.length === 0) return;
    
    const batchSize = Math.min(this.config.batchSize, this.inputQueue.length);
    const batch = this.inputQueue.splice(0, batchSize);
    
    batch.forEach(dataPoint => {
      // Convert to prediction requests based on data type
      const request: PredictionRequest = {
        requestId: `stream_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
        entityId: dataPoint.entityId,
        modelType: this.inferModelType(dataPoint),
        features: dataPoint.data,
        options: {
          ensemble: false,
          confidence: true,
          explanation: false,
          caching: true
        }
      };
      
      this.predictionQueue.push(request);
    });
  }

  private processPredictionQueue(): void {
    if (this.predictionQueue.length === 0) return;
    
    const batchSize = Math.min(this.config.batchSize, this.predictionQueue.length);
    const batch = this.predictionQueue.splice(0, batchSize);
    
    // Process batch asynchronously
    Promise.all(batch.map(request => this.makePrediction(request)))
      .then(results => {
        this.resultQueue.push(...results);
      })
      .catch(error => {
        this.logger.error('Batch prediction processing failed:', error);
      });
  }

  private processResultQueue(): void {
    if (this.resultQueue.length === 0) return;
    
    const results = this.resultQueue.splice(0);
    
    // Emit results
    results.forEach(result => {
      this.emit('prediction_result', result);
    });
  }

  private updateMetrics(): void {
    // Update throughput
    this.metrics.throughput = this.calculateThroughput();
    
    // Update latency percentiles
    this.updateLatencyMetrics();
    
    // Update error rate
    this.updateErrorRate();
    
    // Update cache hit rate
    this.updateCacheMetrics(false);
    
    // Update resource usage
    this.updateResourceUsage();
    
    // Update queue depth
    this.metrics.queueDepth = this.getQueueDepth();
    
    // Check backpressure
    this.metrics.backpressure = this.metrics.queueDepth > (this.config.maxQueueSize * this.config.backpressureThreshold);
  }

  private calculateThroughput(): number {
    // Calculate requests per second
    return this.metrics.throughput; // Simplified
  }

  private updateLatencyMetrics(): void {
    // Update latency percentiles from recent predictions
    // Simplified implementation
  }

  private updateErrorRate(): void {
    // Update error rate from circuit breaker data
    let totalFailures = 0;
    let totalRequests = 0;
    
    this.circuitBreakers.forEach(breaker => {
      totalFailures += breaker.failures;
      totalRequests += breaker.failures + breaker.successes;
    });
    
    this.metrics.errorRate = totalRequests > 0 ? totalFailures / totalRequests : 0;
  }

  private updateCacheMetrics(isHit: boolean): void {
    // Update cache hit rate
    const currentHitRate = this.metrics.cacheHitRate;
    this.metrics.cacheHitRate = isHit ? 
      Math.min(1.0, currentHitRate + 0.01) : 
      Math.max(0.0, currentHitRate - 0.01);
  }

  private updateResourceUsage(): void {
    // Update CPU, memory, GPU usage
    this.metrics.resourceUsage = {
      cpu: process.cpuUsage().user / 1000000, // Convert to seconds
      memory: process.memoryUsage().heapUsed / 1024 / 1024, // MB
      gpu: tf.memory().numBytes / 1024 / 1024 // MB
    };
  }

  private updatePredictionMetrics(result: PredictionResult): void {
    // Update accuracy and other prediction-specific metrics
    this.metrics.accuracy = (this.metrics.accuracy + result.confidence) / 2;
  }

  private recordSuccess(circuitBreaker: CircuitBreaker): void {
    circuitBreaker.successes++;
    
    if (circuitBreaker.state === 'half_open' && 
        circuitBreaker.successes >= circuitBreaker.successThreshold) {
      circuitBreaker.state = 'closed';
      circuitBreaker.failures = 0;
      circuitBreaker.successes = 0;
    }
  }

  private recordFailure(circuitBreaker: CircuitBreaker): void {
    circuitBreaker.failures++;
    circuitBreaker.lastFailureTime = Date.now();
    
    if (circuitBreaker.failures >= circuitBreaker.failureThreshold) {
      circuitBreaker.state = 'open';
    }
  }

  private checkCircuitBreakers(): void {
    this.circuitBreakers.forEach(breaker => {
      if (breaker.state === 'open' && 
          Date.now() - breaker.lastFailureTime > breaker.timeout) {
        breaker.state = 'half_open';
        breaker.successes = 0;
      }
    });
  }

  private performHealthChecks(): void {
    // Perform health checks on all components
    this.healthChecks.set('analytics_engine', true);
    this.healthChecks.set('model_registry', true);
    this.healthChecks.set('feature_store', true);
    
    const healthyComponents = Array.from(this.healthChecks.values()).filter(Boolean).length;
    const totalComponents = this.healthChecks.size;
    
    if (healthyComponents < totalComponents) {
      this.logger.warn(`Health check: ${healthyComponents}/${totalComponents} components healthy`);
    }
  }

  private cleanupCaches(): void {
    const now = Date.now();
    
    // Cleanup prediction cache
    for (const [key, result] of this.predictionCache.entries()) {
      if (now - result.timestamp > this.config.cacheTTL) {
        this.predictionCache.delete(key);
      }
    }
    
    // Cleanup feature cache
    for (const [key, entry] of this.featureCache.entries()) {
      if (now - (entry as any).timestamp > this.config.cacheTTL) {
        this.featureCache.delete(key);
      }
    }
  }

  private emitMetrics(): void {
    this.emit('metrics_update', this.metrics);
  }
}

// Worker interface (simplified)
interface Worker {
  id: number;
  type: string;
  status: 'active' | 'idle' | 'error';
  processor: () => void;
}