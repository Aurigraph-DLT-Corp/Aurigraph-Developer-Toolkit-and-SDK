# Sprint 18: Logstash Configuration for Aurigraph V11 Logs
# Parsing, filtering, and enriching logs from cluster nodes

input {
  # ========== TCP Input from Docker Containers ==========
  tcp {
    port => 5000
    codec => json
    type => "docker"
    tags => ["docker", "aurigraph"]
  }

  # ========== UDP Input (Syslog) ==========
  udp {
    port => 5001
    codec => json
    type => "syslog"
    tags => ["syslog", "aurigraph"]
  }

  # ========== HTTP Input for Log Forwarding ==========
  http {
    port => 8888
    codec => json
    type => "http"
    tags => ["http", "aurigraph"]
  }
}

filter {
  # ========== Docker Metadata Parsing ==========
  if [type] == "docker" {
    # Parse JSON from docker container logs
    if [message] {
      json {
        source => "message"
        target => "json_log"
      }
      
      # Extract fields from JSON log
      mutate {
        add_field => {
          "timestamp" => "%{[json_log][timestamp]}"
          "level" => "%{[json_log][level]}"
          "logger" => "%{[json_log][logger]}"
          "message" => "%{[json_log][message]}"
          "thread" => "%{[json_log][thread]}"
          "hostname" => "%{[json_log][hostname]}"
        }
      }
    }
  }

  # ========== Consensus Log Parsing ==========
  if [logger] =~ /consensus|raft|voting/ {
    mutate {
      add_tag => ["consensus"]
    }
    
    # Parse consensus-specific fields
    grok {
      match => {
        "message" => [
          "voting_round_id=%{GREEDYDATA:voting_round_id}",
          "leader=%{WORD:leader_status}",
          "replication_lag=%{INT:replication_lag:int}",
          "finality_ms=%{INT:finality_ms:int}",
          "active_nodes=%{INT:active_nodes:int}",
          "byzantine_nodes=%{INT:byzantine_nodes:int}"
        ]
      }
      tag_on_failure => ["consensus_parse_error"]
    }
  }

  # ========== Transaction Log Parsing ==========
  if [logger] =~ /transaction|submit|validation/ {
    mutate {
      add_tag => ["transaction"]
    }
    
    grok {
      match => {
        "message" => [
          "tx_id=%{GREEDYDATA:transaction_id}",
          "status=%{WORD:transaction_status}",
          "latency_ms=%{INT:latency_ms:int}",
          "gas_price=%{INT:gas_price:int}",
          "error=%{GREEDYDATA:error_message}"
        ]
      }
      tag_on_failure => ["transaction_parse_error"]
    }
  }

  # ========== Failover/Recovery Log Parsing ==========
  if [logger] =~ /failover|recovery|heartbeat/ {
    mutate {
      add_tag => ["failover"]
    }
    
    grok {
      match => {
        "message" => [
          "node=%{HOSTNAME:failed_node}",
          "detection_ms=%{INT:detection_latency_ms:int}",
          "reelection_ms=%{INT:reelection_latency_ms:int}",
          "new_leader=%{WORD:new_leader}"
        ]
      }
      tag_on_failure => ["failover_parse_error"]
    }
  }

  # ========== Performance Log Parsing ==========
  if [logger] =~ /performance|metrics|optimization/ {
    mutate {
      add_tag => ["performance"]
    }
    
    grok {
      match => {
        "message" => [
          "tps=%{INT:tps:int}",
          "throughput=%{FLOAT:throughput:float}",
          "cpu_usage=%{FLOAT:cpu_usage:float}",
          "memory_usage=%{INT:memory_mb:int}",
          "gc_time_ms=%{INT:gc_time_ms:int}"
        ]
      }
      tag_on_failure => ["performance_parse_error"]
    }
  }

  # ========== Error Log Handling ==========
  if [level] == "ERROR" or [level] == "FATAL" {
    mutate {
      add_tag => ["error", "alert"]
    }
  }

  if [level] == "WARN" {
    mutate {
      add_tag => ["warning"]
    }
  }

  if [level] == "DEBUG" {
    mutate {
      add_tag => ["debug"]
    }
  }

  # ========== Node Identification ==========
  if [hostname] {
    grok {
      match => {
        "hostname" => "aurigraph-v11-(?<node_name>.*)"
      }
      tag_on_failure => ["node_extraction_error"]
    }
  }

  # ========== Timestamp Normalization ==========
  date {
    match => ["timestamp", "ISO8601"]
    target => "@timestamp"
    tag_on_failure => ["timestamp_parse_error"]
  }

  # ========== Geo-IP Enrichment (Optional) ==========
  # if [source_ip] {
  #   geoip {
  #     source => "source_ip"
  #     target => "geoip"
  #   }
  # }

  # ========== Service Enrichment ==========
  mutate {
    add_field => {
      "service" => "aurigraph-v11"
      "cluster" => "aurigraph-cluster"
      "version" => "11.0.0"
      "environment" => "production"
    }
  }

  # ========== Remove Noisy/Verbose Fields ==========
  mutate {
    remove_field => [
      "json_log",
      "host",
      "port",
      "@version"
    ]
  }
}

output {
  # ========== Elasticsearch Output ==========
  elasticsearch {
    hosts => ["https://elasticsearch:9200"]
    user => "elastic"
    password => "${ELASTICSEARCH_PASSWORD}"
    ssl_certificate_authorities => "/usr/share/logstash/certs/ca.crt"
    ssl => true
    verify_mode => "certificate"
    
    # Index naming
    index => "aurigraph-logs-%{+YYYY.MM.dd}"
    
    # Template management
    template_name => "aurigraph-logs"
    template_overwrite => false
    
    # Document ID (optional - for deduplication)
    document_id => "%{[@metadata][document_id]}"
    
    # Pipeline (optional - for additional processing on Elasticsearch side)
    # pipeline => "aurigraph-pipeline"
    
    # Performance settings
    workers => 4
    batch_size => 1000
    timeout => 30
    retry_on_conflict => 3
  }

  # ========== Console Output (Optional - for debugging) ==========
  if [@metadata][debug] {
    stdout {
      codec => rubydebug
    }
  }

  # ========== File Output (Backup) ==========
  # if [level] == "ERROR" or [level] == "FATAL" {
  #   file {
  #     path => "/var/log/aurigraph/%{+YYYY-MM-dd}/errors.log"
  #     codec => json
  #   }
  # }
}
