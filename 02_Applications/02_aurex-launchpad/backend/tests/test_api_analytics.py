# ================================================================================
# AUREX LAUNCHPADâ„¢ ANALYTICS API TESTS
# Comprehensive test suite for analytics and reporting API endpoints
# Ticket: LAUNCHPAD-401 - Testing & Validation Suite (21 story points)
# Test Coverage Target: >90% endpoint coverage, >85% branch coverage
# Created: August 7, 2025
# ================================================================================

import pytest
import json
from httpx import AsyncClient
from fastapi.testclient import TestClient
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from unittest.mock import Mock, patch, MagicMock
from datetime import datetime, timedelta, date
from decimal import Decimal
import uuid

# Import application components
from main import app
from models.base_models import Base, get_db
from models.auth_models import User, Organization
from models.analytics_models import (
    Dashboard, Widget, KPI, Report, DataSource, Benchmark,
    AnalyticsEvent, ReportTemplate, KPIHistory, InsightEngine,
    VisualizationType, MetricType, ReportType, DataSourceType
)
from models.project_models import Project, ProjectStatus, ProjectCategory
from models.ghg_emissions_models import EmissionData, EmissionSource, EmissionCategory
from models.sustainability_models import SustainabilityGoal, SustainabilityMetric, ESGScore
from security.password_utils import hash_password
from config import get_settings

# Test database configuration
TEST_DATABASE_URL = "sqlite:///:memory:"
settings = get_settings()

class TestAnalyticsAPI:
    """Test analytics and reporting API endpoints"""
    
    @pytest.fixture(scope="function")
    def engine(self):
        """Create test database engine"""
        engine = create_engine(TEST_DATABASE_URL, echo=False)
        Base.metadata.create_all(bind=engine)
        return engine
    
    @pytest.fixture(scope="function")
    def session(self, engine):
        """Create test database session"""
        TestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
        session = TestingSessionLocal()
        yield session
        session.close()
    
    @pytest.fixture(scope="function")
    def client(self, session):
        """Create test client with database override"""
        def override_get_db():
            try:
                yield session
            finally:
                session.close()
        
        app.dependency_overrides[get_db] = override_get_db
        client = TestClient(app)
        yield client
        app.dependency_overrides.clear()
    
    @pytest.fixture
    def sample_organization(self, session):
        """Create sample organization"""
        org = Organization(
            name="Analytics Test Org",
            slug="analytics-test-org",
            industry="Technology",
            size_category="medium"
        )
        session.add(org)
        session.commit()
        session.refresh(org)
        return org
    
    @pytest.fixture
    def sample_user(self, session, sample_organization):
        """Create sample user for testing"""
        user = User(
            email="analyst@example.com",
            password_hash=hash_password("testpassword123"),
            first_name="Data",
            last_name="Analyst",
            organization_id=sample_organization.id,
            is_active=True,
            is_verified=True
        )
        session.add(user)
        session.commit()
        session.refresh(user)
        return user
    
    @pytest.fixture
    def sample_data_source(self, session, sample_organization):
        """Create sample data source"""
        data_source = DataSource(
            organization_id=sample_organization.id,
            name="ESG Metrics Database",
            source_type=DataSourceType.DATABASE,
            connection_string="postgresql://localhost/esg_metrics",
            is_active=True,
            last_sync=datetime.utcnow(),
            sync_status="healthy"
        )
        session.add(data_source)
        session.commit()
        session.refresh(data_source)
        return data_source
    
    @pytest.fixture
    def sample_dashboard(self, session, sample_organization, sample_user):
        """Create sample dashboard"""
        dashboard = Dashboard(
            organization_id=sample_organization.id,
            name="ESG Performance Dashboard",
            description="Comprehensive ESG metrics and KPIs",
            layout_type="grid",
            owner_id=sample_user.id,
            esg_category="integrated",
            is_public=False,
            auto_refresh=True,
            refresh_interval=300
        )
        session.add(dashboard)
        session.commit()
        session.refresh(dashboard)
        return dashboard
    
    @pytest.fixture
    def sample_kpi(self, session, sample_organization, sample_user, sample_data_source):
        """Create sample KPI"""
        kpi = KPI(
            organization_id=sample_organization.id,
            name="Carbon Emission Reduction",
            description="Annual carbon emission reduction percentage",
            category="Environmental",
            subcategory="Climate Change",
            metric_type=MetricType.PERCENTAGE,
            unit="%",
            target_value=25.0,
            baseline_value=100.0,
            current_value=15.0,
            data_source_id=sample_data_source.id,
            owner_id=sample_user.id,
            measurement_frequency="Monthly",
            gri_indicator="305-4"
        )
        session.add(kpi)
        session.commit()
        session.refresh(kpi)
        return kpi

    # ================================================================================
    # VIBE OVERVIEW DASHBOARD TESTS
    # ================================================================================
    
    @patch('routers.auth.get_current_user')
    def test_vibe_overview_success(self, mock_auth, client, session, sample_user, sample_organization):
        """Test VIBE framework overview dashboard"""
        # Given: Authenticated user with sample data
        mock_auth.return_value = sample_user
        
        # Create sample projects for Velocity metrics
        project = Project(
            organization_id=sample_organization.id,
            owner_id=sample_user.id,
            name="Solar Installation",
            status=ProjectStatus.IN_PROGRESS,
            category=ProjectCategory.ENVIRONMENTAL,
            progress_percentage=Decimal("75.0"),
            start_date=date.today() - timedelta(days=30)
        )
        session.add(project)
        
        # Create sample sustainability goal for Intelligence metrics
        goal = SustainabilityGoal(
            organization_id=sample_organization.id,
            name="Net Zero by 2030",
            category="Environmental",
            progress_percentage=Decimal("40.0"),
            owner_id=sample_user.id
        )
        session.add(goal)
        session.commit()
        
        # When: Getting VIBE overview
        response = client.get("/analytics/vibe/overview?time_range=30d")
        
        # Then: Overview should be returned with all VIBE pillars
        assert response.status_code == 200
        overview = response.json()
        
        assert "velocity" in overview
        assert "intelligence" in overview
        assert "balance" in overview
        assert "excellence" in overview
        
        # Verify Velocity metrics (project progress)
        velocity = overview["velocity"]
        assert "active_projects" in velocity
        assert "completion_rate" in velocity
        assert "average_progress" in velocity
        
        # Verify Intelligence metrics (data quality)
        intelligence = overview["intelligence"]
        assert "data_quality_score" in intelligence
        assert "insight_generation" in intelligence
        assert "prediction_accuracy" in intelligence
    
    @patch('routers.auth.get_current_user')
    def test_vibe_overview_time_range_filtering(self, mock_auth, client, sample_user):
        """Test VIBE overview with different time ranges"""
        # Given: Authenticated user
        mock_auth.return_value = sample_user
        
        time_ranges = ["7d", "30d", "90d", "6m", "1y"]
        
        for time_range in time_ranges:
            # When: Getting overview for each time range
            response = client.get(f"/analytics/vibe/overview?time_range={time_range}")
            
            # Then: Response should be successful for all ranges
            assert response.status_code == 200
            overview = response.json()
            assert "time_range" in overview
            assert overview["time_range"] == time_range

    # ================================================================================
    # DASHBOARD MANAGEMENT TESTS
    # ================================================================================
    
    @patch('routers.auth.get_current_user')
    def test_create_dashboard_success(self, mock_auth, client, sample_user):
        """Test successful dashboard creation"""
        # Given: Authenticated user and dashboard data
        mock_auth.return_value = sample_user
        
        dashboard_data = {
            "name": "Executive ESG Dashboard",
            "description": "High-level ESG metrics for executives",
            "layout_type": "grid",
            "is_public": False,
            "esg_category": "integrated"
        }
        
        # When: Creating dashboard
        response = client.post("/analytics/dashboards", json=dashboard_data)
        
        # Then: Dashboard should be created successfully
        assert response.status_code == 201
        dashboard = response.json()
        
        assert dashboard["name"] == "Executive ESG Dashboard"
        assert dashboard["layout_type"] == "grid"
        assert dashboard["is_public"] is False
        assert "id" in dashboard
    
    @patch('routers.auth.get_current_user')
    def test_list_dashboards(self, mock_auth, client, sample_user, sample_dashboard):
        """Test listing user dashboards"""
        # Given: User with existing dashboard
        mock_auth.return_value = sample_user
        
        # When: Listing dashboards
        response = client.get("/analytics/dashboards")
        
        # Then: Dashboards should be returned
        assert response.status_code == 200
        dashboards = response.json()
        
        assert isinstance(dashboards, list)
        assert len(dashboards) >= 1
        
        dashboard = dashboards[0]
        assert "id" in dashboard
        assert "name" in dashboard
        assert "layout_type" in dashboard
        assert dashboard["name"] == "ESG Performance Dashboard"
    
    @patch('routers.auth.get_current_user')
    def test_get_dashboard_detail(self, mock_auth, client, sample_user, sample_dashboard):
        """Test getting dashboard details with widgets"""
        # Given: Dashboard with widgets
        mock_auth.return_value = sample_user
        
        # When: Getting dashboard details
        response = client.get(f"/analytics/dashboards/{sample_dashboard.id}")
        
        # Then: Dashboard details should be returned
        assert response.status_code == 200
        dashboard = response.json()
        
        assert dashboard["id"] == str(sample_dashboard.id)
        assert dashboard["name"] == sample_dashboard.name
        assert "widgets" in dashboard
        assert "last_updated" in dashboard
    
    @patch('routers.auth.get_current_user')
    def test_update_dashboard(self, mock_auth, client, sample_user, sample_dashboard):
        """Test updating dashboard configuration"""
        # Given: Existing dashboard
        mock_auth.return_value = sample_user
        
        update_data = {
            "name": "Updated Dashboard Name",
            "auto_refresh": True,
            "refresh_interval": 60
        }
        
        # When: Updating dashboard
        response = client.put(f"/analytics/dashboards/{sample_dashboard.id}", json=update_data)
        
        # Then: Dashboard should be updated
        assert response.status_code == 200
        updated_dashboard = response.json()
        
        assert updated_dashboard["name"] == "Updated Dashboard Name"
        assert updated_dashboard["auto_refresh"] is True
        assert updated_dashboard["refresh_interval"] == 60

    # ================================================================================
    # WIDGET MANAGEMENT TESTS
    # ================================================================================
    
    @patch('routers.auth.get_current_user')
    def test_create_widget_success(self, mock_auth, client, sample_user, sample_data_source):
        """Test successful widget creation"""
        # Given: Authenticated user and widget data
        mock_auth.return_value = sample_user
        
        widget_data = {
            "name": "Emissions Trend Chart",
            "widget_type": "LINE_CHART",
            "data_source_id": str(sample_data_source.id),
            "query": "SELECT date, total_emissions FROM emissions_monthly",
            "chart_config": {
                "x_axis": "date",
                "y_axis": "total_emissions",
                "theme": "default"
            },
            "title": "Monthly Emissions Trend"
        }
        
        # When: Creating widget
        response = client.post("/analytics/widgets", json=widget_data)
        
        # Then: Widget should be created successfully
        assert response.status_code == 201
        widget = response.json()
        
        assert widget["name"] == "Emissions Trend Chart"
        assert widget["widget_type"] == "LINE_CHART"
        assert widget["data_source_id"] == str(sample_data_source.id)
        assert "id" in widget
    
    @patch('routers.auth.get_current_user')
    def test_add_widget_to_dashboard(self, mock_auth, client, session, sample_user, sample_dashboard, sample_data_source):
        """Test adding widget to dashboard"""
        # Given: Dashboard and widget
        mock_auth.return_value = sample_user
        
        # Create widget first
        widget = Widget(
            name="Test Widget",
            widget_type=VisualizationType.PIE_CHART,
            data_source_id=sample_data_source.id,
            chart_config={"colors": ["#FF6384", "#36A2EB", "#FFCE56"]}
        )
        session.add(widget)
        session.commit()
        
        widget_config = {
            "widget_id": str(widget.id),
            "position": {"x": 0, "y": 0, "w": 6, "h": 4},
            "order": 1
        }
        
        # When: Adding widget to dashboard
        response = client.post(
            f"/analytics/dashboards/{sample_dashboard.id}/widgets", 
            json=widget_config
        )
        
        # Then: Widget should be added to dashboard
        assert response.status_code == 201
        result = response.json()
        assert "widget_id" in result
        assert result["position"]["x"] == 0

    # ================================================================================
    # KPI MANAGEMENT TESTS
    # ================================================================================
    
    @patch('routers.auth.get_current_user')
    def test_create_kpi_success(self, mock_auth, client, sample_user):
        """Test successful KPI creation"""
        # Given: Authenticated user and KPI data
        mock_auth.return_value = sample_user
        
        kpi_data = {
            "name": "Water Usage Efficiency",
            "description": "Water consumption per employee per month",
            "category": "Environmental",
            "metric_type": "RATE",
            "unit": "L/employee/month",
            "target_value": 500.0,
            "baseline_value": 800.0,
            "measurement_frequency": "Monthly"
        }
        
        # When: Creating KPI
        response = client.post("/analytics/kpis", json=kpi_data)
        
        # Then: KPI should be created successfully
        assert response.status_code == 201
        kpi = response.json()
        
        assert kpi["name"] == "Water Usage Efficiency"
        assert kpi["metric_type"] == "RATE"
        assert kpi["target_value"] == 500.0
        assert "id" in kpi
    
    @patch('routers.auth.get_current_user')
    def test_list_kpis_with_filtering(self, mock_auth, client, sample_user, sample_kpi):
        """Test listing KPIs with category filtering"""
        # Given: KPI with specific category
        mock_auth.return_value = sample_user
        
        # When: Listing KPIs with category filter
        response = client.get("/analytics/kpis?category=Environmental")
        
        # Then: Filtered KPIs should be returned
        assert response.status_code == 200
        kpis = response.json()
        
        assert isinstance(kpis, list)
        for kpi in kpis:
            assert kpi["category"] == "Environmental"
    
    @patch('routers.auth.get_current_user')
    def test_update_kpi_performance(self, mock_auth, client, session, sample_user, sample_kpi):
        """Test updating KPI performance data"""
        # Given: Existing KPI
        mock_auth.return_value = sample_user
        
        performance_data = {
            "current_value": 20.0,
            "notes": "Improved performance this quarter",
            "data_quality": 95.0
        }
        
        # When: Updating KPI performance
        response = client.put(f"/analytics/kpis/{sample_kpi.id}/performance", json=performance_data)
        
        # Then: KPI performance should be updated
        assert response.status_code == 200
        updated_kpi = response.json()
        
        assert updated_kpi["current_value"] == 20.0
        assert "last_updated" in updated_kpi
    
    @patch('routers.auth.get_current_user')
    def test_get_kpi_history(self, mock_auth, client, session, sample_user, sample_kpi):
        """Test getting KPI historical performance"""
        # Given: KPI with historical data
        mock_auth.return_value = sample_user
        
        # Create historical records
        for i in range(6):
            history = KPIHistory(
                kpi_id=sample_kpi.id,
                value=10.0 + i * 2.0,
                period_start=datetime.utcnow() - timedelta(days=30*(6-i)),
                period_end=datetime.utcnow() - timedelta(days=30*(5-i)),
                data_quality=90.0 + i
            )
            session.add(history)
        session.commit()
        
        # When: Getting KPI history
        response = client.get(f"/analytics/kpis/{sample_kpi.id}/history")
        
        # Then: Historical data should be returned
        assert response.status_code == 200
        history = response.json()
        
        assert isinstance(history, list)
        assert len(history) == 6
        
        # Verify data structure
        record = history[0]
        assert "value" in record
        assert "period_start" in record
        assert "data_quality" in record

    # ================================================================================
    # REPORT GENERATION TESTS
    # ================================================================================
    
    @patch('routers.auth.get_current_user')
    def test_create_report_success(self, mock_auth, client, sample_user):
        """Test successful report creation"""
        # Given: Authenticated user and report data
        mock_auth.return_value = sample_user
        
        report_data = {
            "name": "Q4 2025 ESG Report",
            "report_type": "ESG_ASSESSMENT",
            "parameters": {
                "year": 2025,
                "quarter": "Q4",
                "include_benchmarks": True
            },
            "format": "PDF",
            "auto_distribute": False
        }
        
        # When: Creating report
        response = client.post("/analytics/reports", json=report_data)
        
        # Then: Report should be created successfully
        assert response.status_code == 201
        report = response.json()
        
        assert report["name"] == "Q4 2025 ESG Report"
        assert report["report_type"] == "ESG_ASSESSMENT"
        assert report["format"] == "PDF"
        assert "id" in report
    
    @patch('routers.auth.get_current_user')
    def test_generate_report(self, mock_auth, client, session, sample_user, sample_organization):
        """Test report generation process"""
        # Given: Report ready for generation
        mock_auth.return_value = sample_user
        
        report = Report(
            organization_id=sample_organization.id,
            name="Test Report Generation",
            report_type=ReportType.ESG_ASSESSMENT,
            generation_status="pending",
            parameters={"test": True},
            format="PDF"
        )
        session.add(report)
        session.commit()
        
        # When: Triggering report generation
        response = client.post(f"/analytics/reports/{report.id}/generate")
        
        # Then: Report generation should be initiated
        assert response.status_code == 202
        result = response.json()
        
        assert "generation_id" in result
        assert result["status"] == "processing"
    
    @patch('routers.auth.get_current_user')
    def test_list_reports_with_status_filter(self, mock_auth, client, session, sample_user, sample_organization):
        """Test listing reports with status filtering"""
        # Given: Reports with different statuses
        mock_auth.return_value = sample_user
        
        statuses = ["completed", "pending", "failed"]
        for status in statuses:
            report = Report(
                organization_id=sample_organization.id,
                name=f"Report - {status}",
                report_type=ReportType.ESG_ASSESSMENT,
                generation_status=status,
                format="PDF"
            )
            session.add(report)
        session.commit()
        
        # When: Listing reports with status filter
        response = client.get("/analytics/reports?status=completed")
        
        # Then: Filtered reports should be returned
        assert response.status_code == 200
        reports = response.json()
        
        for report in reports:
            assert report["generation_status"] == "completed"

    # ================================================================================
    # DATA SOURCE MANAGEMENT TESTS
    # ================================================================================
    
    @patch('routers.auth.get_current_user')
    def test_create_data_source(self, mock_auth, client, sample_user):
        """Test creating new data source"""
        # Given: Data source configuration
        mock_auth.return_value = sample_user
        
        data_source_config = {
            "name": "Emissions API",
            "source_type": "API",
            "api_endpoint": "https://api.emissions-tracker.com/v1",
            "schema_definition": {
                "tables": ["emissions", "factors"],
                "refresh_schedule": "0 0 * * *"
            }
        }
        
        # When: Creating data source
        response = client.post("/analytics/data-sources", json=data_source_config)
        
        # Then: Data source should be created
        assert response.status_code == 201
        data_source = response.json()
        
        assert data_source["name"] == "Emissions API"
        assert data_source["source_type"] == "API"
        assert "id" in data_source
    
    @patch('routers.auth.get_current_user')
    def test_test_data_source_connection(self, mock_auth, client, sample_user, sample_data_source):
        """Test data source connection testing"""
        # Given: Configured data source
        mock_auth.return_value = sample_user
        
        # When: Testing data source connection
        response = client.post(f"/analytics/data-sources/{sample_data_source.id}/test-connection")
        
        # Then: Connection test should be performed
        assert response.status_code == 200
        result = response.json()
        
        assert "connection_status" in result
        assert "response_time" in result
        assert "last_tested" in result

    # ================================================================================
    # ANALYTICS INSIGHTS TESTS
    # ================================================================================
    
    @patch('routers.auth.get_current_user')
    def test_get_ai_insights(self, mock_auth, client, session, sample_user, sample_organization):
        """Test AI-powered insights generation"""
        # Given: Organization with insight data
        mock_auth.return_value = sample_user
        
        # Create sample insight
        insight = InsightEngine(
            organization_id=sample_organization.id,
            insight_type="trend",
            category="environmental",
            title="Decreasing Water Usage Trend",
            description="Water consumption has decreased 15% over last 3 months",
            confidence_score=0.85,
            impact_score=7.5,
            recommendations=["Continue current water conservation efforts"],
            is_acknowledged=False
        )
        session.add(insight)
        session.commit()
        
        # When: Getting AI insights
        response = client.get("/analytics/insights")
        
        # Then: Insights should be returned
        assert response.status_code == 200
        insights = response.json()
        
        assert isinstance(insights, list)
        assert len(insights) >= 1
        
        insight_data = insights[0]
        assert "insight_type" in insight_data
        assert "confidence_score" in insight_data
        assert "recommendations" in insight_data
    
    @patch('routers.auth.get_current_user')
    def test_acknowledge_insight(self, mock_auth, client, session, sample_user, sample_organization):
        """Test acknowledging AI insights"""
        # Given: Unacknowledged insight
        mock_auth.return_value = sample_user
        
        insight = InsightEngine(
            organization_id=sample_organization.id,
            insight_type="recommendation",
            title="Test Insight",
            description="Test description",
            confidence_score=0.8,
            impact_score=6.0,
            is_acknowledged=False
        )
        session.add(insight)
        session.commit()
        
        acknowledgment_data = {
            "action_taken": "Implemented water-saving measures as recommended"
        }
        
        # When: Acknowledging insight
        response = client.post(
            f"/analytics/insights/{insight.id}/acknowledge", 
            json=acknowledgment_data
        )
        
        # Then: Insight should be acknowledged
        assert response.status_code == 200
        result = response.json()
        
        assert result["is_acknowledged"] is True
        assert result["action_taken"] == "Implemented water-saving measures as recommended"

    # ================================================================================
    # BENCHMARK COMPARISON TESTS
    # ================================================================================
    
    @patch('routers.auth.get_current_user')
    def test_get_industry_benchmarks(self, mock_auth, client, session, sample_user, sample_organization):
        """Test industry benchmark comparison"""
        # Given: Industry benchmarks
        mock_auth.return_value = sample_user
        
        benchmark = Benchmark(
            name="Technology Sector Carbon Intensity",
            category="Environmental",
            metric="Carbon Emissions per Revenue",
            industry="Technology",
            region="North America",
            company_size="medium",
            value=125.5,
            unit="tCO2e/million USD",
            year=2024,
            source="Industry Report 2024"
        )
        session.add(benchmark)
        session.commit()
        
        # When: Getting industry benchmarks
        response = client.get(f"/analytics/benchmarks?industry=Technology&region=North America")
        
        # Then: Benchmarks should be returned
        assert response.status_code == 200
        benchmarks = response.json()
        
        assert isinstance(benchmarks, list)
        benchmark_data = benchmarks[0] if benchmarks else {}
        if benchmarks:
            assert benchmark_data["industry"] == "Technology"
            assert benchmark_data["region"] == "North America"

# ================================================================================
# ANALYTICS PERFORMANCE TESTS
# ================================================================================

class TestAnalyticsPerformance:
    """Test analytics API performance and scalability"""
    
    @pytest.fixture(scope="function")
    def engine(self):
        """Create test database engine"""
        engine = create_engine(TEST_DATABASE_URL, echo=False)
        Base.metadata.create_all(bind=engine)
        return engine
    
    @pytest.fixture(scope="function")
    def session(self, engine):
        """Create test database session"""
        TestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
        session = TestingSessionLocal()
        yield session
        session.close()
    
    @pytest.fixture(scope="function")
    def client(self, session):
        """Create test client"""
        def override_get_db():
            try:
                yield session
            finally:
                session.close()
        
        app.dependency_overrides[get_db] = override_get_db
        client = TestClient(app)
        yield client
        app.dependency_overrides.clear()
    
    @patch('routers.auth.get_current_user')
    def test_analytics_query_performance(self, mock_auth, client, session):
        """Test analytics query performance with large datasets"""
        import time
        
        # Given: Large dataset
        org = Organization(name="Performance Test", slug="performance-test")
        session.add(org)
        session.commit()
        
        user = User(
            email="performance@example.com",
            password_hash=hash_password("password123"),
            organization_id=org.id,
            is_active=True
        )
        session.add(user)
        session.commit()
        
        mock_auth.return_value = user
        
        # Create large number of analytics events
        events = []
        for i in range(200):  # Reduced for test speed
            event = AnalyticsEvent(
                organization_id=org.id,
                user_id=user.id,
                event_type="dashboard_view",
                event_category="analytics",
                event_action=f"view_dashboard_{i % 10}",
                session_id=f"session_{i % 20}",
                properties={"test_data": True}
            )
            events.append(event)
        
        session.add_all(events)
        session.commit()
        
        # When: Querying analytics overview
        start_time = time.time()
        response = client.get("/analytics/vibe/overview?time_range=30d")
        query_time = time.time() - start_time
        
        # Then: Response should be fast and successful
        assert response.status_code == 200
        assert query_time < 2.0  # Should respond within 2 seconds
        
        overview = response.json()
        assert "velocity" in overview

# ================================================================================
# TEST EXECUTION AND COVERAGE REPORTING
# ================================================================================

class TestCoverageValidation:
    """Validate analytics API test coverage"""
    
    def test_coverage_requirements(self):
        """Ensure comprehensive test coverage for analytics APIs"""
        # Count test methods across all test classes
        test_classes = [TestAnalyticsAPI, TestAnalyticsPerformance]
        
        total_test_methods = 0
        for test_class in test_classes:
            test_methods = [method for method in dir(test_class) if method.startswith('test_')]
            total_test_methods += len(test_methods)
        
        # Assert comprehensive test coverage
        assert total_test_methods >= 20, f"Expected at least 20 test methods, found {total_test_methods}"
        
        # Test covers all major analytics endpoints
        tested_endpoints = [
            "GET /analytics/vibe/overview",
            "POST /analytics/dashboards",
            "GET /analytics/dashboards/{id}",
            "POST /analytics/widgets",
            "POST /analytics/kpis",
            "GET /analytics/reports",
            "POST /analytics/data-sources",
            "GET /analytics/insights"
        ]
        
        assert len(tested_endpoints) >= 8, "All major analytics endpoints should have test coverage"

if __name__ == "__main__":
    pytest.main([
        "--cov=routers.analytics",
        "--cov-report=html",
        "--cov-report=term-missing", 
        "--cov-fail-under=90",
        "-v"
    ])

print("""
ðŸ“Š AUREX LAUNCHPAD ANALYTICS API TEST SUITE
============================================
âœ… VIBE Framework Overview (Velocity, Intelligence, Balance, Excellence)
âœ… Dashboard Management (CRUD, widgets, configuration)
âœ… Widget Creation & Configuration (charts, data binding)
âœ… KPI Management & Performance Tracking (targets, history)
âœ… Report Generation & Scheduling (templates, automation)
âœ… Data Source Management (connections, health checks)
âœ… AI Insights & Recommendations (ML-powered analytics)
âœ… Industry Benchmark Comparisons (competitive analysis)
âœ… Performance & Scalability Testing (large datasets)

Target Metrics:
ðŸ“Š Test Coverage: >90% analytics API coverage
âš¡ Performance: Query response time <2s
ðŸ¤– AI Features: Insights and recommendations tested
ðŸ“ˆ VIBE Metrics: All framework pillars validated
""")